# JVM

## 第一章 走进java

> ### 为什么学习java虚拟机
>
> * JVM为达到平台无关性而牺牲了一部分性能特性
> * 开发人员不了解JVM特性和原理，无法为写出高效目标代码
>
> ### java技术体系
>
> * java技术体系组成部分
>   * java程序设计语言
>   * 运行在各种硬件平台上的JVM实现
>   * .class文件格式
>   * java类库api
>
> * JRE
>   * java类库api的一个子集
>   * JVM
>
> * Java SE
>   * API核心包是 **java.*** 
>
> * Java EE
>   * API拓展包多是 **javax.***
>
> ### 热点代码探测
>
> * 通过执行计数器找出最具有编译价值的代码
> * 然后通知即时编译器以方法为单位进行编译
>
> ### Graal虚拟机
>
> * 特点
>   * 无语言倾向
>   * 不同语言可以互相混合调用对方接口和对象
>   * 支持每种语言已经编写好的本地库
>
> * 支持语言
>   * 本身运行在JVM上的java、kotlin等语言
>   * 基于llvm的C、C++、RUST语言
>
> * 工作原理
>   * 将语言的源代码或者源代码编译后的中间形式通过解释器转换成GraalVM识别的中间格式(IR)
>   * 如 C -> LLVM IR -> Graal IR -> VM执行 -> 结果
>
> * 高级特点
>   * 和指令集一样只与机器物理特性相关而与某种特定高级语言无关
>
> ### HotSpot内的编译器
>
> * 客户端编译器
>   * 编译时间短但优化程度低
>
> * 服务端编译器
>   * 编译时间长但优化程度高
>
> ### 提前编译
>
> * 优势
>   * 提前编译好直接用，不用等即时编译
>   * 减少java第一次运行慢的特点
>
> * 劣势
>   * 必须为每个硬件、操作系统去编译对应的发行包
>   * 降低了动态性，要求链接在编译前全部已知
>
> **************

## 第二章 内存区域和内存溢出

> ### 概述
>
> * C、C++和Java
>   * 关于内存管理。外面的人想进去，里面的人想出来
> * 自动管理内存的缺点
>   * 一旦java发生内存泄漏。如果对JVM是如何使用内存不了解，那排查错误将异常费劲
>
> ### 运行时数据区域
>
> * 线程独有
>   * 程序计数器
>   * 虚拟机栈
>   * Native栈
> * 线程公有
>   * 堆
>   * 方法区
>     * 常量池
>
> ### 与C++的区别
>
> * 所有的内存区域都会映射到`JVM`这个进程对应的`虚拟地址空间上`
> * 在讨论Java相关的内存问题、对象问题、方法执行问题时不要和C++那一套联系起来，它们有关联但区别也很大，联系起来容易搞混
>
> ### 程序计数器
>
> * 实质
>   * 是一块较小的内存空间
> * 作用
>   * 和C语言的PC寄存器一样
>   * 指向的是当前所执行的`字节码`
> * 执行区别
>   * 当执行一个java方法时指向正在执行的虚拟机字节码指令地址
>   * 当执行一个native方法，计数器值为空
>
> ### java虚拟机栈
>
> * 特点
>   * 生命周期与线程生命周期相同
> * 栈帧包含内容
>   * 局部变量表
>   * 操作数栈
>   * 动态链接
>   * 方法出口
>   * ……
>   * 注意：返回地址存放在局部变量表中，不放在栈结尾，和C语言不同
> * 局部变量表
>   * 存放内容
>     * 编译期可知的基本数据类
>     * 编译期可知的对象引用(即对象在堆中的地址)
>     * **函数返回地址** (java的函数返回地址不放在栈结尾)
>   * 存放单位
>     * 局部变量槽
>     * 一个槽的大小一般是`32 bit`
>   * 大小
>     * 局部变量表大小在编译期就可以确定
>     * 方法运行期不会改变局部变量表的大小
> * 八大基本数据类型
>   * `byte,char,short,int,long`
>   * `float,double`
>   * `boolean`
> * 内存异常
>   * StackOverFlowError —— 请求栈深度大于虚拟机允许最大深度
>
> ### 本地方法栈
>
> * 作用
>   * 和虚拟机栈几乎一样
>   * 只不过本地方法栈执行本地native方法
>
> * HotSpot
>   * 此虚拟机甚至本地方法栈和虚拟机栈合二为一
>
> ### 堆
>
> * 特点
>   * JVM启动时即创建堆
> * 唯一作用
>   * 存放java对象的实例
>   * 注：由于逃逸分析技术发展，出现了`栈上分配、标量替换`技术，因此对象全在栈上说法不能太绝对
> * 堆空间分类
>   * java堆空间不进行分类，因为它的作用只有一个就是存放对象实例
>   * 如果进行分类也是为了更好地进行垃圾回收
> * 堆大小参数
>   * `-Xmx`
>   * `-Xms`
> * 空间连续性
>   * java虚拟机规范允许java堆在物理内存上不连续，但它们在逻辑上应该是连续的
>
> ### 方法区
>
> * 存放内容
>   * 已被虚拟机加载的类型信息
>   * 已被虚拟机加载的常量
>   * 已被虚拟机加载的静态变量
>   * 即时编译器编译后的代码缓存数据
> * 存放内容的特点
>   * 几乎不需要修改
>   * 几乎都需要常驻内存
>   * 由上方法区曾被称作**永久代**
> * 回收内容
>   * 常量池的回收
>   * 类型的卸载
>     * 要卸载一个类型条件极其苛刻，尝尝不会进行卸载
> * 方法区实现
>   * JDK8使用本地内存(`native memory`)技术实现方法区
>   * 即直接使用`JVM`进程的`虚拟地址空间`内存来进行存放
>
> ### 运行时常量池
>
> * 实质
>   * 是方法区的一部分
>
> * 存放内容
>   * 编译期生成的各种字面量和符号引用，因为这部分内容大多在`class`文件的常量池表中，因此要等类加载完毕后才会将这些信息存入运行时常量池
>   * 运行时产生的新的常量(具有动态性)
>
> ### 直接内存
>
> * 实质
>   * 不是运行时数据区的一部分，而是堆外的一部分内存
>   * 也就是`JVM`进程虚拟地址空间的一部分内存
> * 使用方式
>   * 使用`native`函数分配堆外内存，通过堆中的一个`DirectByteBuffer`对象间接进行访问
> * 作用
>   * 使用此内存区域来避免`java堆`和`native堆`频繁交换数据，提高效率
>
> ### 字符串常量池
>
> * 概念
>   * 具体实现在底层看不到了，总之非常的智能
>   * 人一眼能看出来的相等字符串，大概率就是相等的同一个对象，优化手段很厉害
> * 自己总结的放入池子时机
>   * 编译时`String a = "abc";`这种直接写`"abc"`
>   * 运行时生成了`String`对象，常常是`toString`方法
>   * `String.intern()`时池子里面没有
>
> ### 对象的创建
>
> * 对象界定
>   * 此处对象指java普通对象，不包括数组和`Class对象`
>
> * A - 检查类的符号引用
>   * 检查常量池中是否有`此类的符号引用`
>   * 当有引用时，检查类是否`已加载、解析、初始化`。如果没有就执行`类加载`过程
>   
> * B - 分配内存
>   * 内存大小在类加载完成时就可以确定
>   * 在内存中分配此对象规定大小的内存
>
> * 分配内存方式
>   * 指针碰撞式
>     * 内存绝对完整
>     * 仅仅移动指针就能完成内存分配
>     * 适合带空间压缩整理的GC
>   * 空闲列表式
>     * 维护一个空闲和占用表
>     * 分配完内存就改表
>     * 适合不带空间整理的GC
>
> * 分配内存时处理线程安全
>   * 方法一：把分配内存空间动作同步处理
>     * 可以采用`CAS`操作配上失败重试
>   * 方法二：使用本地线程分配缓冲TLAB
>     * 在堆中为每个线程分配一小块内存
>     * 对于每个线程来说这块内存是私有的
>     * 分配空间时先在TLAB内分配
>     * 当TLAB用完重新分配缓存区时才同步锁定
>   
> * C - 赋值0
>   * 分配完后除了`对象头`外全部赋值为0
>   * 这样能保证对象的实例字段不赋初始值就能够直接使用，使数据类型都有零值
>
> * D - 设置对象头
>   * 对象头是对象内存区域的一部分
>
> * E - 执行构造函数
>
> ### 对象内存布局
>
> * 内存部分
>   * 对象头
>   * 实例数据
>   * 对齐填充
>
> * 对象头数据
>   * 对象自身的运行时数据(尽可能节约空间多存放信息内容)
>     * 哈希码
>     * GC分代信息
>     * 锁标志
>     * ……
>   * 类型元数据的指针
>     * 如果是数组还要存储数组的长度，因为要通过对象直接直到对象的大小
>   
> * 实例数据
>   * 参数顺序有变，尽量节约内存
>
> * 对齐
>   * 必须要求8字节对齐
>
> ### 对象访问定位
>
> * 句柄访问
>   * 访问原理
>     * 在堆内存中划分一部分作为句柄池
>     * 虚拟机栈中的reference指向句柄池中的一个句柄
>   * 句柄内容
>     * 到对象实例的指针
>     * 到对象类型数据的指针
>   * 缺点
>     * 间接访问
>     * 需要一部分堆内存空间作为句柄池
>   * 优点
>     * 由于对象移动是很常见的操作(由于GC)，因此移动时可以只修改句柄中两个引用的地址而不用修改栈引用的地址
> * 直接访问
>   * 虚拟机栈中的reference直接指向堆内存中的实例对象数据
>   * 实例数据中有一个指针指向方法区的类型信息
> * HotSpot
>   * HotSpot虚拟机使用直接访问
>
> ### 实战堆OOM异常
>
> * 指令
>
>   ```bash
>   java -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError HeapOOM
>   ```
>   * 这些参数都是虚拟机启动参数，用于控制虚拟机启动
>   * **Xms20m** —— 堆内存大小是20M
>   * **Xmx20m** —— 最大堆内存可以扩展到20M
>   * **-XX:+HeapDumpOnOutOfMemoryError** —— 出现堆内存异常时dump出信息，会生成hprof文件供分析使用
>
> * 代码
>
>   ```java
>   import java.util.ArrayList;
>   public class HeapOOM{
>       	//声明一个对象待会儿来占用堆内存
>           static class OOMObject{}
>           public static void main(String[] args){
>                   //创建一个数组保持引用不要被GC回收
>                   ArrayList<OOMObject> list = new ArrayList<OOMObject>();
>                   //一直创建占用堆内存
>                   while(true){list.add(new OOMObject());}
>           }
>   }
>   ```
>
> * 堆溢出常见原因
>   * 循环创建对象存储在堆内存中
>
> ### 实战SOF异常
>
> * 指令
>
>   ```bash
>   java -Xss228k StackSOF 
>   ```
>   * **Xss228k** —— 栈大小是228k(栈不可拓展，因此无Xsx)
>
> * 代码
>
>   ```java
>   public class StackSOF{
>       	//创建一个循环无限递归函数来压栈帧
>           static void increase(){
>                   int i = 0;
>                   increase();
>           }
>           public static void main(String[] args){
>                   //调用函数
>                   increase();
>           }
>   }
>   ```
>
> * 栈溢出原因
>   * 原因一
>     * 递归调用函数使栈帧循环压栈
>   * 原因二
>     * Java多线程是采取直接映射到内核线程上的方式
>     * 可能由于线程太多使`JVM`进程本身的虚拟地址空间的`栈区域`满而导致溢出
>     * 这样给每个栈分配空间越大，随着线程数的增长，极有可能把本地内存给整爆
>     * 因此栈空间不是分配得越大越好
>   
> * 调优注意
>   * 对于低位的操作系统如32位，一个进程的最大内存很有限
>   * 此系统如果想要程序有尽可能多的线程的话
>   * 通常采用减少最大堆，减少栈容量来解决。因为这样就能能容纳更多的线程了
>   * 此条调优比较隐蔽
>
> ### 方法区/常量池溢出
>
> * `String::intern()`方法
>
>   * 首先在常量池中找有没有这个字符串
>   * 如果有就直接返回这个字符串的引用
>   * 当常量池中没有时就在常量池中创建一个字符串并返回此字符串的引用
>   * 当常量池溢出时会抛出OOM异常
>
> * 代码
>
>   ```java
>   import java.util.HashSet;
>   public class RuntimeConstPoolOOM{
>           public static void main(String[] args){
>                   //用来存引用防止GC
>                   HashSet<String> set = new HashSet<String>();
>                   int i = 0;
>                   //循环创建字符串
>                   while(true){set.add(String.valueOf(++i).intern());}
>           }
>   }
>   ```
>
> * 注意
>   * JDK8及以后字符串常量池在堆中
>
> * 常量池有意思举例
>
>   ```java
>   String str1 = new StringBuilder("jahhhhhhhhhh").append("va").toString();
>   System.out.println(str1.intern() == str1);
>
>   String str2 = new StringBuilder("ja").append("va").toString();
>   System.out.println(str2.intern() == str2);
>   ```
>   * 第一个输出true。
>   * 第二个输出false。因为StringBuilder对象肯定在堆中，堆中一开始就有了java这个字符串。因此str2.intern()首先去常量池中就找到了之前的，自然与新创建的不同
>
> * 溢出原因
>   * 原因一
>     * 常量创建得太多如String使常量池堆溢出
>   * 原因二
>     * 创建得类太多，类型信息使内存溢出
>     * 举例
>       * 操作字节码动态生成大量类，这在`Spring`框架中很常见
>
> ### 本机内存直接溢出
>
> * 直接内存大小
>   * 默认与java堆内存一样大，即 `-Xmx声明`大小
>
> ************

## 第三章 垃圾回收与内存分配机制

> ### 概述
>
> * 垃圾收集完成的三件事
>   * 回收什么？
>   * 怎样回收？
>   * 什么时候回收？
> * 学习原因
>   * 可以排查各种内存泄漏，内存溢出问题
>   * 当垃圾收集成为限制系统达到更高并发量时
> * PC、虚拟机栈、本地方法栈
>   * 这是线程私有的，生命周期与线程同步。不太需要进行垃圾回收
>   * 这几个内存区域比较简单，内存大小几乎都可以在编译期就知道
>   * 特别是栈就是方法栈帧压栈出栈，不用内存回收
> * 堆、方法区
>   * 这部分内存有着很强的不确定性
>     * 一个接口不同的实现类需要分配的内存大小是不一样的
>     * 一个方法执行不同分支需要的内存大小也是不一样的
>     * 只有处于运行期间才知道到底要创建多少个对象
>   * 这部分内存的分配与回收是动态的
> * 内存回收含义
>   * 以下内存回收的内存就是指的堆和方法区内存
>
> ### 引用计数法
>
> * 原理
>
>   * 在对象中添加一个引用计数器
>   * 引用增加则计数器加1
>   * 引用减少则计数器减1
>   * 引用数目为0代表是垃圾
>
> * 缺点
>
>   * 虽然简单，但需要考虑很多额外的情况才能使算法正确的运行
>   * 比如互相引用问题，导致它们引用计数器不为零，然而它们确实是可以回收的垃圾
>
> * 打印内存回收日志参数
>
>   ```bash
>   java -XX:+PrintGCDetails GCTest
>   ```
>
> ### 可达性分析
>
> * 原理
>   * 通过一系列`GC Root`根对象作为起始节点集(即根节点不只一个)
>   * 然后根据是否有引用关系(图论术语就是是否可达)来判断对象是否是垃圾
> * GC Root种类
>   * 虚拟机栈中引用的对象
>   * 方法区中的静态属性引用的变量
>   * 方法区中常量引用的对象
>   * 本地栈(通常和虚拟机栈一样)JNI引用的对象
>   * JVM内部的引用
>     * 基本数据类型对应的Class对象
>     * 常驻异常对象如(NPE, OOM)
>     * 系统类加载器
>   * 所有被同步锁(`synchronized`关键字)持有的对象
>   * 其他`临时性`对象
>     * 比如隔代引用的对象
>
> ### 在谈引用
>
> * 传统引用的狭隘性
>   * 有些对象当内存够的时候就可以保留，内存不够就不想保留它。对于这样情况传统的引用定义不能区分
>   * 比如很多系统的缓存功能就复合上面的这种定义
> * 强引用
>   * 就是传统的引用
>   * 只要有强引用就不会被GC
>
> * 软引用
>   * 引用一些还有用但非必须的对象
>   * 当系统快OOM时回收这部分对象
>   * API提供了`SoftReference`类来实现软引用
>
> * 弱引用
>   * 用来描述非必须对象
>   * 下一次GC时不管有无引用都会回收掉弱引用对象
>   * API提供`WeakReference`类来实现弱引用
>
> * 虚引用
>   * 是最弱的一种引用关系
>   * 虚引用是否存在，完全不影响其生存事件，也无法通过虚引用来访问一个对象
>   * 虚引用唯一目的是当GC时收到一个系统通知
>   * API提供`PhantomReference`来实现虚引用
>
> ###  回收方法区
>
> * 概述
>   * `JVM规范`提到过可以不要求虚拟机在方法区实现垃圾回收。事实上确实有未实现类型卸载的垃圾收集器存在
> * 回收的低效率
>   * 对堆进行一次内存回收通常可以释放`70% -99 %`的内存空间
>   * 而对方法区进行垃圾回收通常内存释放效率较低
> * 方法区垃圾分类
>   * 不再使用的常量
>   * 不再使用的类型信息
> * 常量垃圾回收
>   * 和对象的回收非常类似
>   * 即整个系统中没有在对这个常量的引用
> * 类型垃圾回收条件
>   * 该类的所有实例都已经被回收
>   * 加载该类的类加载器被回收
>     * 这个条件很难达到，除非是经过精心设计的可替换类加载器的场景。如`OSGi`
>   * 该类对应的`java.lang.Class`对象没有在任何地方被引用，即不能在通过反射创建对象
> * 被允许
>   * 满足上面条件仅仅是达到`被允许`回收条件
>   * 虚拟机还提供了一些参数来控制是否支持类型卸载，如`-Xnoclassgc`
> * 类型卸载的必要性
>   * 类型爆炸情况
>     * 大量使用反射创建对象
>     * 动态代理
>     * CGLib字节码框架等
>     * `OSGi`这类频繁定义类加载器的场景
>   * 必要性
>     * 上面的场景通常要JVM具备类型卸载的能力，不然容易`OOM`
>
> ### 垃圾回收算法
>
> * 从如何判定对象消亡角度分类
>   * `reference counting GC`——  直接GC
>   * `tracing GC` —— 间接GC
> * 我们只讨论`间接GC`，引用计数这种GC不考虑
>
> ### 分代收集理论
>
> * 理论假说
>   * 弱分代假说 —— 绝大多数对象是朝生夕灭的
>   * 强分代假说 —— 熬过越多次垃圾回收的对象越难被回收
>   * 跨代引用假说 —— 跨代引用相对于同代引用来说仅仅占少数
> * 设计原则
>   * GC器应该对Java堆做划分
>   * 根据对象年龄将不同的对象划分到不同的堆内存区域进行存储
>   * 对不同的区域采取不同的收集策略，兼顾时间和空间
> * 回收类型划分
>   * Minor GC = Young GC
>   * Major GC = Old GC
>   * Full GC
> * 收集简介
>   * 新生代收集：关注存活对象逐步把它升级到老年代，其他内存释放
>   * 老年代收集：关注被收集对象将其释放收集
> * 跨代引用
>   * 现状
>     * 跨代引用比较少
>   * 解决方式
>     * 在新生代维护一个全局数据结构 —— 记忆集(`Remembered Set`)
>     * 这个数据结构标记老年代那一部分的内存存在对新生代的跨代引用
>     * 新生代收集时只把老年代被标记部分内存的对象加进`GC root`集合进行扫描
>   * 优劣分析
>     * 为何记忆集会增加一些开销
>     * 但相比于将整个老年代加进`GC root`集合来说，还是非常划算的
>
> ### 标记清除算法
>
> * 算法思想
>   * 标记所有将回收的，不标记不回收的。标记完成后GC，然后清楚标记
>   * 反过来标记不回收的，不标记要回收的
> * 算法缺点
>   * 效率不稳定
>     * 标记和清楚的时间和对象数量多少正相关
>   * 内存碎片太多
>     * 标记和清出去造成了大量的内部碎片
>
> ### 标记复制算法
>
> * 出现原因
>   * 解决`标记复制`当对象多时回收效率低
>   * 能解决原因：它直接把一块内存不再使用默认为零，即几乎没有`回收`这个过程
> * 适用情况
>   * 新生代
>   * 存活对象相对很少
> * 算法思想
>   * 将新生代划分为8:1:1
>     * 8叫做`Eden`
>     * 1叫做`Survivor`
>   * 每次内存分派只使用8和其中一个1
>   * 每次进行GC就将还存活的对象复制进另外一个1，然后把8和本身的1清除掉
>   * 重复上述操作
> * 缺点
>   * 内存空间有浪费，永远最多只能使用百分之九十的空间
>   * 对象存活率大的情况效果很差，因为复制增多
>   * 当存活对象大于`10%`时会触发老年代`分配担保`机制
>     * 简单来说就是这部分大于`10%`的对象不足以存放在`survivor`中，通过分配担保直接存入老年代
>
> ### 标记整理算法
>
> * 适用情况
>   * 老年代
> * 算法思想
>   * 还是首先行标记
>   * 将所有存活的对象向一端进行移动
>   * 然后清楚掉边界以外的内存
> * 缺点
>   * 老年代存活对象那么多，移动效率太低，而且这种对象移动操作必须`stop the world`
> * 回收与分配的冲突
>   * 复杂性方面
>     * 不整理方便回收但不利于分配
>     * 整理方便分配但不利于回收
>   * 停顿时间方面
>     * 不整理停顿时间短，甚至不需要停顿
>     * 整理移动对象会`stop the world`
> * 吞吐量
>   * 内存分配和内存回收的效率总和
> * 解决方式
>   * 看中吞吐量老年代就标记整理
>     * 如`Parallel Scavenge`收集器
>   * 看中延迟老年代就标记清除
>     * 如`CMS`收集器
> * 折中方式
>   * 先进行标记清除
>   * 当内存碎片严重到已经无法进行内存分配时在进行标记整理
>   * 上面看中延迟的`CMS`收集器当内存碎片过多时就采取这种方式
>
> ### 两类算法区分
>
> * 对象判定算法
>   * 计数法
>   * 可达法
> * 垃圾收集算法
>   * 标记清除法
>   * 标记复制法
>   * 标记整理法
>
> ###  根节点枚举
>
> * 现状待解决问题
>   * 根节点一般位于虚拟机栈和方法区中
>   * 方法区中的根节点就已经恒河沙数了。查找遍历及其耗时
>   * 目前所有GC器在进行根节点枚举时都必须暂停用户线程`stop the world`
>   * 在查找引用链能做到并发但枚举根节点目前依然做不到并发，因为要保证根节点枚举过程中对象的引用关系不发生变化
>
> * 解决方法
>   * 使用准确式垃圾收集，提前存储虚拟机栈和方法区什么地方是引用(根节点)
>   * 存储方式是使用OopMap数据结构(普通对象指针集合)
>   * 一旦类加载动作完成，就会计算什么偏移量是什么类型的数据；即时编译过程中，也会在特定的位置记录下栈和寄存器那些位置是引用
>   * 然后在`stop the world`时进行枚举时能够快速枚举出结果
> * OopMap处理逻辑
>   * 在指令执行时修改`OopMap`
>   * 例如调用与OopMap相关的指令，指出那个寄存器，栈上那个位置是引用且有效的截止范围
>   * 如：`OopMap{ ebx = oop, [16] = oop off = 142}`
>   * 即这是`JVM`字节码指令层面的实现
>
> ### 安全点
>
> * 出现原因
>   * 如果每一条指令都生成对应的OopMap，那将极其地复杂，成本太高
> * 实质
>   * 只在某些特定的位置才记录`OopMap`信息
>   * 这些位置就称为安全点
>
> * 特点
>   * 强制用户程序代码只能在执行到达安全点后才能暂停进行根节点枚举，否则不能进行
>   * 安全点不能太多也不能太少
>     * 太多 —— 增大内存运行负荷
>     * 太少 —— 让收集器等待时间过长
>   * 选取标准
>     * 是否让程序具有长时间执行的特征
>   * 标准解释
>     * 单纯的指令流太长一般不会导致这段指令运行时间长，因为每条指令运行时间极短
>     * 运行时间长一般只会因为指令序列复用处，如方法调用，循环跳转，异常跳转等等
>     * 一般只有具有这些功能的指令才会产生安全点
>
> * 主动式中断
>   * 目的
>     * 为了能让垃圾收集时所有线程都能到安全点，以便`stop the world`进行根节点枚举
>   * 实现
>     * 不直接对线程进行操作，而是设置一个标志位
>     * 执行期间一直轮询这个标志位，一旦标志位为真就在最近的安全点中断挂起
>     * 轮询标志的地方和安全点是重合的
>
> * 轮询实现
>   * 使用`内存保护陷阱`异常控制流来实现。把轮询操作精简到只有一条`汇编指令`
>   * `JVM`需要`stop the world`时就设置某`虚拟内存`页为不可读
>   * 线程执行`test %eax, 0x160100`汇编指令就会产生陷阱异常信号，`ECF`主动跳转到预先定义的异常处理程序，异常处理程序会把线程挂起，即实现了`stop the world`
>   * 轮询标志的地方和安全点是重合的，即有安全点的地方必然有轮询指令
>   * 轮询指令也会出现在需要堆内存分配的地方，用来检查是否堆空间不足而需要收集
>
> ### 安全区域
>
> * 出现原因
>   * 安全点无法解决线程被`sleep、blocked`的状态
> * 实质
>   * 是线程的代码序列流中的一段，此段引用关系不会发生变化，在此段进行垃圾回收不会有影响
>   * 可以看做是安全点的延伸
> * 作用
>   * 当一些线程没有分配处理器时间，如被Sleep，block的线程无法在即将垃圾回收时继续执行到安全点
> * 安全区实现安全原理
>   * 当一个线程进入安全区时，首先标记自己进入安全区，那么GC就与自己无关
>   * 当它想出安全区时，如果GC未完成它就被阻塞锁住
> * 个人猜想
>   * 当一个被阻塞的线程阻塞处于不是安全区，当它可以继续执行时。如果此时没在GC就继续执行，如果此时正在GC就还是被阻塞直到GC结束才恢复运行
>
> ### 记忆集与卡表
>
> * 背景
>   * 所有涉及分区域收集的GC都有跨代引用的问题
>   * 而记忆集是专门为了解决跨代引用而存在的
> * 目的
>   * 假设AB两个区域中对B区域进行垃圾收集
>   * 如果不使用记忆集则因为A区域可能会存在对B区域的引用，则要把A区域的所有对象全部加进`GC root`
>   * 而有了记忆集就可以不全部加入，只把部分有引用关系的A区域的对象加入`GC root`就行了
> * 定义
>   * 记录从非收集区到收集区的指针集合的抽象数据结构
> * 粗粒度
>   * 原因
>     * 不同的粒度有不同的存储和维护成本
>   * 粒度选择
>     * 字长精度
>     * 对象精度
>     * 卡精度 —— 最常用
>   * 选择
>     * 由于完全没必要详尽记录跨代引用的全部细节，只需要知道存在一个引用即可
>     * 因此可以采用粗粒度的`卡精度`，比如卡表来实现记忆集
> * 记忆集与卡表之间关系
>   * 记忆集是一个抽象的接口概念，只定义了行为意图
>   * 卡表是遵循记忆集意图的一个实现，定义了行为的具体体现
> * HotSpot卡表
>   * 本质
>     * 一个字节数组
>   * 实现方式
>     * 新生代卡表数组每一个元素代表老年代内存的一个卡页(2的整次幂大小)
>     * 当老年代内存某卡页存在至少一个跨代引用时，就将此新生代卡表数组对应元素设置成1
>     * GC时只将数组为1的对应内存放进GC Root扫描
>
> ### 写屏障 (write  barrier)
>
> * 前述
>   * 出现原因之一
>     * 如何维护卡表？什么时候设置卡表变脏(将卡页设置为1)
>   * 卡表变脏时刻
>     * 引用类型字段赋值的那一刻
>   * 遇到问题
>     * 解释执行的字节码
>       * 还可以接受，虚拟机负责每条字节码的执行，有充足的介入空降
>     * 即时编译过后的机器码
>       * 比较棘手，已经是纯粹的机器指令流了，必须找到一个在机器码层面的手段。在每次赋值过程中更新卡表
> * 实质
>   * 在虚拟机层面对`引用类型字段赋值`这个动作的AOP切面
>     * 实际上就是动态代理
>   * 在引用赋值的时候会产生一个`环形通知`，供程序执行额外的动作
>   * 赋值的前后都在写屏障的范围内
>     * 即写前屏障和写后屏障
>     * 即写屏障的范围完全包含了赋值的动作
> * 缺点
>   * 只要发生了引用类型字段赋值这个动作就要在写屏障范围内更新卡表
>   * 然而很多字符赋值根本不是跨代引用，就产生了额外开销
>   * 不过这个额外开销相对于将整个老年代添加进`GC root`还是要好很多
> * 伪共享问题
>   * 卡表是一个数组，每个元素的大小都不大，极其容易发生伪共享问题
>   * 当多个线程修改互相独立的变量时
>   * 如果这些变量恰好共享同一个缓存行
>   * 就会出现彼此影响而导致性能降低
> * 伪共享解决方法
>   * 并发读同一个缓存行没有问题，只有并发写才有问题
>   * 那就在写前加一个判断。如果卡表元素已经是1了就不用写
>   * 这样减少了写的次数解决了伪共享问题，但增加了判断开销。如何权衡根据情况考虑
>
> ### 并行的可达性分析
>
> * 目前问题
>   * 枚举GC Root要暂停所有用户线程，这是确定的。但至少有Oop Map优化。且`stop the world`时间不随堆容量增加而增加了，它相对固定
>   * 从GC Root向下遍历对象问题就十分大了，时间开销几乎与java堆大小成正比
>   * 必须保证在一致性的快照下才能进行对象图的遍历。不然不是垃圾的可能会被错误标记为垃圾。
> * 三色标记
>   * 白色 —— 表示尚未被垃圾收集器访问过。最后还是白色就是垃圾
>   * 黑色 —— 表示本对象且此对象的所有引用都被扫描过。表示不是垃圾且不会被扫描
>   * 灰色 —— 表示本对象已经扫描但此对象至少还有一个引用没有扫描
>
> * 导致并发错误(不是垃圾的被当成了垃圾)的唯二原因
>   * 赋值器插入了至少一条从黑色对象到白色对象的新引用
>   * 赋值器删除了全部从灰色对象到白色对象的直接或间接引用
>   * 注 —— 以上二原因要同时满足才会导致，单独满足一个不会导致
>
> * 解决措施
>   * 原因一 —— 增量更新
>   * 原因二 —— 原始快照
>
> * 增量更新
>   * 记录下新增的引用关系
>   * 并发扫描结束后将引用关系中的黑色对象为更重新扫描
>
> * 原始快照
>   * 记录下删除的引用关系
>   * 并发扫描结束后，将引用关系中灰色对象为根，重新扫描
>
> * 两种引用变更记录的实现机制
>   * 写屏障
>
> ### 解释执行与即时(JIT)编译
>
> * 解释执行
>   * 对于字节码，JVM一边把它编译成机器码，一边执行
> * 即时编译
>   * JVM根据热点探测技术，提前找到高频执行代码，比如循环
>   * 首先把其编译机器码
>   * 然后直接执行
>
> * 解释执行优缺点
>   * 优点
>     * JVM对代码的可操作性大
>     * JVM能对代码进行优化
>     * 能看到更多的中间过程
>   * 缺点
>     * 运行速度慢
>     * 第一次解释执行的话尤其慢
>
> * 即时执行优缺点
>   * 优点
>     * 执行速度快且高效
>   * 缺点
>     * JVM可操作性太低
>     * 无法进行优化
>     * 不知道中间过程
>
> ### 垃圾回收时机
>
> * 新生代
>   * Eden空间不足
> * Full GC
>   * 新生代晋升老年代太多导致空间不足
>   * 大对象进入导致空间不足
>   * 新生代分配担保机制导致老年代收集
>   * 并发失败
>
> ### Serial收集器
>
> * 简介
>   * 非常古老原始
>   * 顾名思义是单线程GC
> * 特点
>   * 收集处 —— 新生代
>   * 算法 —— 标记复制
>   * 适用处 —— 客户端
> * 缺点
>   * GC时必须暂停所有用户线程，造成stop the world现象
> * GC 努力方向
>   * 降低用户线程停顿时间
>   * 但目前只能降低仍无法根除这个问题
> * 优势
>   * 简单高效
>   * 额外内存消耗(FootPrint)最少
>   * 对于单线程或者线程少的场景效果起始还很好。且没有线程间开销
>   * 由上，在用户端运行的JVM采用Serial GC来收集新生代起始挺不错
>
> ### ParNew收集器
>
> * 实质
>   * 就是Serial GC的多线程版本
> * 特点
>   * 收集处 —— 新生代
>   * 算法 —— 标记复制
>   * 线程 —— 多线程并行但不并发
>   * 适用处 —— 服务端(因为服务端多核)
>
> * 简介
>   * 代码很多和Serial一模一样
>   * 在单线程里还打不过serial，只有在多线程里才能取胜
>
> * parallel与concurrent
>   * parallel —— 一个GC多条线程间的关系
>   * concurrent —— GC线程和用户线程的关系
>
> ### Parallel Scavenge收集器
>
> * 实质
>   * 关注吞吐量的Parallel New收集器
>
> * 特点
>   * 适用处 —— 新生代
>   * 线程 —— 多线程并行
>   * 算法 —— 标记复制
>
> * 吞吐与延迟
>   * 低延迟代表良好的用户交互和服务响应
>   * 高吞吐代表可以最高效率地利用处理器资源，尽快完成计算任务
>
> * 核心要素
>   * 此款GC关注吞吐量而不是延迟
>   * 其他的GC很多都是关注延迟
>
> * 控制吞吐量的相关参数
>   * **-XX: MaxGCPauseMillis** —— 设置GC的最长时间，实质上就是设置延迟，高延迟能带来高吞吐
>   * **-XX:GCTimeRatio** —— 作用和上面类似
>
> * 别名
>   * 吞吐量优先GC
>
> * 动态调整特性
>   * parallel scavenge GC能够自适应调节，动态调整收集器参数
>   * 此特性对于那些对收集器运作不清楚的程序员来说是好事
>
> ### Serial old
>
> * 特点
>   * 适用区 —— 老年代
>   * 算法 —— 标记整理
>   * 线程 —— 单线程(顾名思义)
>   * 适用 —— 客户端模式
>
> * 特殊情况
>   * 在CMS发生failure的时候救场备用
>
> ### Parallel old
>
> * 实质
>   * Parallel New的老年版本
>
> * 特点
>   * 适用区 —— 老年代
>   * 线程 —— 多线程并行
>   * 算法 —— 标记整理
>
> * 服务端特点
>   * 服务端的处理器和处理器核心数一般都比较多
>   * 因此服务端肯定要用带有并行处理能力的GC
>
> ### CMS (concurrent mark sweep)
>
> * 目标
>   * 获取最短回收停顿时间。又被叫做低延迟垃圾收集器
> * 特点
>   * 算法 —— 标记清除
>   * **收集区域 —— 老年区**
>   * 多线程并行，用户线程并发
>   * 低停顿
> * 四个步骤
>   * 初始标记
>     * 非并发，需要`stop the world`
>     * 仅仅标记 GC Root和GC Root能直接引用的对象
>   * 并发标记
>     * 遍历整个对象图
>     * 可以和用户线程并发，且此步用时最长
>   * 重新标记
>     * 并发标记过程中可能引用关系会改变，需要重新标记(`详情见增量更新`)
>     * 这一步需要`stop the world`
>   * 并发清除
>     * 清除被标记的对象
>     * 这一步由于采用`标记清除算法`不用移动活的对象，因此这一步也可以并发
> * 核心优点
>   * 并发收集
>   * 低延迟
>   * 因此又被称为`并发低停顿`收集器
> * 三个缺点
>   * 对处理器资源敏感
>     * 面向并发的程序对处理器资源都比较敏感
>     * GC线程会占用一部分处理器资源，虽然用户进程没有停下来但速度会降低
>     * 解决思路： 增量式并发收集器 (现在已被弃用)
>       * 收集线程和用户线程的调度方式使用抢占式调度
>       * 这样虽然GC收集的总时间会变长，但用户程序就不会感觉那么慢
>   * 无法处理浮动垃圾
>     * 并发标记和并发清除这个过程中会产生新的垃圾
>     * 在标记过程结束以后出现的垃圾就是浮动垃圾
>     * 因为浮动垃圾存在CMS在老年代达到一定占用时就必须开始收集，而不是等满了才收集
>     * 而且当预留内存无法满足新对象分配需要时，需要使用`Serial Old`来重新收集老年代垃圾，这是需要`stop the world`的。因此将`CMS`老年代达到的百分之多少的阈值才开始收集的参数设置得太高会导致`concurrent failure`
>   * 容易产生内存碎片
>     * 标记清除算法会导致内存碎片
>     * 因为内存碎片可能会导致老年代无法分配对象，触发`Full GC`
>     * 或者设置参数当老年代快满时进行`标记整理`，然而整理`目前`还是要`stop the world`的，因此又得停顿
>
> ### G1 (garbage first)
>
> * 特点
>   * 面向局部收集的设计思路
>   * 基于`region`内存布局形式
>   * 停顿时间模型
>     * 在`M`秒的时间内，垃圾回收所占的时间不超过`N`秒
>   * 全功能垃圾收集器
>     * 支持类型卸载
>   * 多线程并行，用户线程并发
> * 接隔离
>   * `统一垃圾接口`，即想将垃圾收集的行为与实现进行分离。因为之前耦合得太严重了
> * 回收差异
>   * 之前回收内容
>     * 整个新生代
>     * 整个老年代
>     * 整个堆
>   * G1回收内容
>     * 内存`region`集合 `collection set`
>   * G1回收标准
>     * 那些`region`的垃圾最多，回收收益最大
> * region
>   * 概念
>     * 将整个堆划分为大小相等的很多个`region`
>     * 每个`region`可以根据需要，扮演`eden、suvivor或者old`空间
>     * 不同职责的`region`采取不同的收集策略
>   * `humongous region`
>     * 是区别于普通`region`的一个`region`
>     * 作用：专门用于存放大对象
>     * 判定大对象标准：一个对象所占空间超过`region`区域的一半
>     * 超大对象存储：连续占据多个`region`
>     * G1将`humongous region`视作老年代
> * 停顿时间模型
>   * 用户能够指定在一个M毫秒的时间段内，消耗在GC的时间不超过N毫秒。即可以指定GC的时间
>   * 因为回收对象是region集合，因此每次回收内存大小必定是region大小的整数倍
>   * 在后台维护一个优先级表，优先值是每块region的回收价值
>   * 根据用户设置的GC参数在优先表中选择适当的region进行回收就能设置收集停顿时间
> * `region`之间跨引用
>   * 依旧使用记忆集方法，但记忆集的实现更复杂
>   * 因为每个region都可能存在跨region引用，因此每个region都有记忆集
>   * 由于记忆集那么多，因此G1收集器在GC时占用的堆内存就会比较高
> * 并发用户线程干扰
>   * G1采用原始快照，CMS采取增量更新
>   * 每个region都有两个名为TAMS的指针，指针间的区域用于并发途中新对象创建
>   * 指针区域对象进行GC时默认存活不收集
>   * 如果指针区域不足以容纳并发中新对象的分配，依然会冻结线程`stop the world`然后进行full gc
> * 可靠的停顿预测
>   * 以衰减均值理论为根据
>   * 衰减均值相对于普通均值的区别是其时效性更强，更能反映当前region的回收价值
>   * 在GC时会记录诸如回收耗时、标准偏差、置信度等统计信息
> * 回收过程
>   * 初始标记
>     * 非并发
>     * 仅仅标记GC Root直接访问到的对象
>     * 修改TAMS指针的初始值
>   * 并发标记
>     * 递归标记GC Root以下的结点
>     * 记录原始快照有变动的记录
>   * 最终标记
>     * 非并发
>     * 处理原始快照SATB
>   * 筛选回收
>     * 非并发，由于采取标记复制算法，需要移动对象
>     * 注: G1每次标记是全堆都进行了标记，但扫描只扫描回收集内的region。和后面ZGC不同
>     * 更新region统计数据，将`region`按照回收价值排序，根据用户设置制定收集计划
>     * 自由选择回收哪一些region(构成回收集)，把存活对象复制到哪一些另外的region，然后清理掉整个region
> * 定位
>   * 并非纯粹准求低延迟(因为四个过程只有一个能并发)
>   * 定位是在延迟可控的情况下获得尽可能高的吞吐量
> * 设置期望停顿时间
>   * 设置停顿时间可以在不同的应用场景中取得吞吐量和延迟之间的平衡
>   * 停顿目标如果太短，会导致一次只能GC很小一部分，导致GC速度更不上allocate速度，导致无堆内存，导致stop the world，然后full GC
> * 设计思路改变
>   * 旧 
>     * 一次收集尽可能多的内存，恨不得报java堆清理干净
>   * 新
>     * 只要收集的速度能够跟上分配的速度就行
> * G1优点
>   * 可以指定最大停顿时间
>   * 面向region收集
>   * 按收益动态调整回收处
>   * 由于未采用标记清除算法，因此无内存碎片
> * G1算法
>   * 整体上基于标记整理
>   * 局部(两个region之间)上基于标记复制
> * G1缺点
>   * 内存占用偏高 —— 如卡表维护更复杂，每个`region`都有卡表
>   * GC额外负载偏高 —— 如`写后屏障`维护卡表，`写前屏障`维护并发标记指针变化实现`原始快照`
>
> ### 低延时GC
>
> * 三个指标和不可能三角
>   * 内存占用 - (footprint)
>   * 吞吐量 - (throughout)
>   * 延迟 - (latency)
> * 目前延迟的重要性越来越大，因为其他两个都可以随着硬件提高而提高，而延迟并不会
>
> ### ZGC收集器
>
> * 目标
>
>   * 回收任意堆内存大小都能把垃圾收集的停顿时间(不是回收时间)限制在10ms以内
>
> * 停顿时间与回收时间
>
>   * 停顿时间是指回收过程中暂停用户线程stop the world的时间
>   * 回收时间是指GC的整个时间
>
> * 简要概括
>
>   * ZGC是一款基于region内存布局，(暂时)不设分代，使用读屏障、染色指针和内存多重映射等技术实现并发标记整理的，以低延迟为主要目标的垃圾收集器
>
> * region的动态性
>
>   * G1的region是固定大小的，而ZGC的region具有动态性
>
>   * 动态体现在动态创建销毁，动态容量
>
>   * ##### region的三种容量
>
>     * 小型 —— 固定2M，要求对象小于256k
>     * 中型 —— 固定32M，要求对象小于4M
>     * 大型 —— 容量必须是2的整倍数。只能存放一个对象(对象复制代价相对很高)，大型容量不一定比中型大
>
> * 染色指针技术特点
>
>   * 这些信息只供GC或者虚拟机本身使用，而不会被对象访问使用(如对象头某一些信息)
>   * 从与对象指针和内存本身无关的地方获取信息
>   * 如标记过程给对象打三色标记，标记信息只与对象引用有关而与对象本身无关
>   * 标记位置方案 —— 对象头，与对象无关的数据结构上，指针上
>
> * 染色指针核心
>
>   * 64位的指针根本不需要用64位，可以用其中一些位来表示信息
>   * 染色指针将本身用来表示内存的46位中的高4位用来存储四个标记信息
>   * 由于只用了本来用来内存寻址的4位，ZGC只支持4TB内存，不支持32位，只支持linux系统(目前)
>
> * 四个标记
>
>   * **marked 0** —— 与marked 1一起确定对象的三色状态
>   * **marked 1** —— 与marked 0一起确定对象的三色状态
>   * **remapped** —— 是否进入了重分配集(是否被移动过)
>   * **finalizable** —— 是否只有通过finalize()方法才能访问
>
> * 优势
>
>   * 一旦某个region的存活对象被全部移走之后，这个region就能马上被释放和重用。不必等待整个堆中所有指向该region的引用都被修正后在清理
>   * 大幅度减少垃圾收集过程中内存屏障的使用数量(因为内存屏障通常是为了记录对象引用改变，而现在这个改变是放在染色指针进行维护的。且ZGC不支持分代，就没记忆集而减少屏障使用)
>   * 可以作为一种可拓展的存储结构用来记录更多与对象标记、重定位过程相关的数据，以便日后提高性能
>
> * 多重映射虚拟内存
>
>   * 目的 —— 解决物理处理器不认指针上额外信息，只把指针当寻址地址的问题
>   * 多重原因 —— 不同标记的相同地址的指针值不同但却是同一个物理地址
>
> * 并发标记
>
>   * 和之前的并发标记一样，只不过标记中途的信息记录在染色体指针里
>   * 同样分为初始标记，冲突整理，重新标记
>
> * 并发预备重分配
>
>   * 根据查询条件统计出那些region组成分配集(relocation set)
>   * ZGC每次都会扫描所有region，用更大范围扫描换取记忆集维护成本
>   * 重分配集只是决定了这些集合内的存活对象会被复制到其他region中，然后将集合释放掉
>   * 回收行为针对的集合范围比分配集大，因为标记过程针对的是全堆
>
> * 并发重分配
>
>   * 此阶段是核心阶段
>   * 将重分配集中的存活对象复制到其他region，并为每个重分配集的region维护一分自己的转发表
>   * 由于有染色指针，仅仅从指针就能判断一个对象是否位于重分配集
>   * 自愈 —— 用户线程访问重分配集中的对象，触发内存屏障，根据转发表访问复制后的对象，在将原来的引用修改为新的引用
>   * 自愈优势 —— 仅仅只慢一次，后面的访问就正常不会触发内存屏障；复制完毕就能把region释放重用，只有保留转发表
>
> * 并发重映射
>
>   * 目的：修正整个堆中指向重分配集中旧对象的所有引用
>   * 进行时机：下一次并发标记时
>   * 滞后原因：修正不迫切，用户线程访问完全可以通过自愈；并发标记需要遍历所有对象，这样能节约一次遍历开销
>
>   * 全部修正后就能释放转发表了
>
> * 停顿时间与堆容量关系
>
>   * ZGC的停顿时间只与GC Root数量有关，与堆容量大小无关
>   * 但整个回收时间还是与堆容量有关的
>
> * GC速率可能赶不上分配速率
>
>   * 产生原因： 由于没有采用分代回收，不能对需要高频大量回收的新生代做相应的回收策略改变而是整个堆一锅端一起回收，导致一次回收消耗的时间可能很长，导致浮动垃圾使堆溢出，然后导致Full GC 
>   * 解决方法一：尽可能增大堆容量，但这种方法不长久
>   * 根本解决方法：引入分代机制
>
> * ZGC支持NUMA-Aware内存分配
>
>   * NonUniform Memory Access
>   * 是一种为多核处理器或多处理器计算机设计的内存架构，是一种内存架构
>   * 由于摩尔定律失效，原来的提升性能的高频路线被迫换成多核路线
>   * 每个处理器都有一个内存控制器，都有自己能够快速访问的一部分内存，访问其他处理器内存就要通过中介速度降低
>   * ZGC为了速度会在多核心的后端上优先尝试请求当前线程处理器的本地内存上分配对象
>
> * 未来定位
>
>   * 服务端，多核心，大内存，低延迟首选
>
> * 非商业性质原因
>
>   * 不支持全平台，只支持linux
>   * 不支持类型卸载
>   * 不支持Graal编译器
>   * 上面的支持都只是时间问题
>
> ### Epsilon收集器
>
> * 核心特点
>   * 不能进行垃圾收集的垃圾器
>
> * 垃圾收集器职责
>   * 堆的管理与布局
>   * 对象的分配
>   * 与解释器协作
>   * 与编译器协作
>   * 与监控子系统协作
>   * not only GC
>
> * 近年趋势
>   * 传统单体应用向微服务化、无服务化发展
>   * 传统java项目内存占用大，在容器中启动时间长、即时编译需要缓存(不适合微服务)
>
> * 适用情况
>   * 在运行时间很短，只需要JVM能够正确分配内存就行的项目
>
> ### 收集器权衡
>
> * 三项指标
>   * 吞吐量 —— 如数据分析，科学计算想尽快出结果
>   * 延迟 —— BS结构系统
>   * 内存占用 —— 嵌入式系统或者微型客户端
>
> ### GC日志
>
> * t框架
>
>   * JVM有统一的日志框架，和`Android`的日志框架一样
>   * 可以筛选`tag、level`。其中垃圾回收的tag是`gc`
>
> * gc参数
>
>   * jdk9之前使用`-XX: +PrintGCDetails`；之后使用`-X-log:gc*`可以打印出所有`gc日志`信息用来分析
>
>     ```bash
>     [Full GC (Ergonomics) [PSYoungGen: 43513K->23126K(620544K)] [ParOldGen: 101404K->109897K(221184K)] 144918K->133024K(841728K), [Metaspace: 77276K->76763K(1120256K)], 0.3217926 secs] [Times: user=1.55 sys=0.06, real=0.32 secs]
>     ```
>
> ### 对象优先在Eden区分配
>
> * 大多数情况
>
>   * 对象在新生代的Eden区分配
>   * 当Eden区不足时，会触发Minor GC
>
> * 示例代码
>
>   ```java
>   public class TestAllocation{
>           public static final int _1MB = 1024*1024;
>           public static void main(String[] args){
>                   byte[] b1,b2,b3,b4;
>                   b1 = new byte[2*_1MB];
>                   b2 = new byte[2*_1MB];
>                   b3 = new byte[2*_1MB];
>                   b4 = new byte[4*_1MB];
>           }
>   }
>   ```
>
> * 运行指令
>
>   ```shell
>   java11 -Xms20M -Xmx20M -Xmn10M -Xlog:gc* TestAllocation
>   ```
>
>   * -Xms 堆最小为20M
>   * -Xmx 堆最大为20M
>   * -Xmn 新生代为10M
>
> * 运行分析
>
>   * 执行到b4时，新生代的Eden总共8M被分了6M，无法在分配4M
>   * 于是第一次gc发生，但发现无GC内容，于是触发分配担保。把6M对象移到了老年代
>   * 最后退出结果为Eden共8M占用4M，老年代共10M占用6M
>
>   ```bash
>   Heap
>    PSYoungGen      total 9216K, used 6979K [0x00000000ff600000, 0x0000000100000000, 0x0000000100000000)
>     eden space 8192K, 85% used [0x00000000ff600000,0x00000000ffcd0ee8,0x00000000ffe00000)
>     from space 1024K, 0% used [0x00000000fff00000,0x00000000fff00000,0x0000000100000000)
>     to   space 1024K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x00000000fff00000)
>    ParOldGen       total 10240K, used 4096K [0x00000000fec00000, 0x00000000ff600000, 0x00000000ff600000)
>     object space 10240K, 40% used [0x00000000fec00000,0x00000000ff000010,0x00000000ff600000)
>    Metaspace       used 2485K, capacity 4486K, committed 4864K, reserved 1056768K
>     class space    used 266K, capacity 386K, committed 512K, reserved 1048576K
>   ```
>
> ### 大对象直接进入老年代
>
> * 目的
>
>   * 避免大对象在`eden和old`间进行复制
>
> * 大对象坏处
>
>   * 大对象复制开销大
>   * 大对象分配常常会进行内存整理以腾出足够大的空间进行分配
>   * 朝生夕灭的大对象是最烦的，系统非常难顶
>
> * 大对象参数
>
>   * **-XX:+PretenureSizeThreshold**  进入老年期对象大小门槛
>
> * 指令
>
>   ```shell
>   java11 -Xms20M -Xmx20M -Xmn10M -XX:PretenureSizeThreshold=4M -Xlog:gc* TestAllocation
>   ```
>
> ### 长期存活对象进入老年代
>
> * gc分代年龄默认15就会进入老年代
> * 可以使用`-XX:MaxTenruingThreshold`参数来调整
>
> ### 动态年龄判定
>
> * **-XX:MaxTenuringThreshold = 15**进入老年代的最低年龄
> * 但不一定必须要等到`15`才能进入老年代
> * 当`survivor`空间中相同的年龄的对象占据`survivor`空间超过一半时，这部分对象就可以直接进入老年代
>
> ### 空间分配担保
>
> * `minor gc`判断顺序
>   * 老年代剩余空间是否大于新生代所有对象总空间？如果大于就`minnor gc`，否则进行下面判断
>   * 查看`-XX:HandlePromotionFailure`参数是否允许分配担保失败？如果不允许直接`full gc`，如果允许进行下面判断
>   * 查看老年代剩余空间是否大于历次晋升到老年代对象总空间的平均大小？如果大于就`minnor gc`，否则直接`full gc`
> * 担保失败
>   * `full gc`
>
> ### 小结
>
> * 没有完美全能的垃圾收集器
> * 要学会选择合适的
>
> ***

## 第六章 类文件结构

> ### 概述
>
> * 之前我们把程序编译成`二进制本地机器代码`
> * 现在我们可以选择与`操作系统和指令集无关、平台中立`的格式作为程序编译后存储的格式
>
> ### 无关性的基石
>
> * 基石
>   * 字节码
> * 平台无关性
>   * `JVM`只认`class`文件格式
>   * 不同平台下编译的class字节码可以在其他任何一个平台执行
> * 语言无关性
>   * 目前`java`正在朝着语言无关性发展，Graal VM就是一个例子
>   * 语言无关性的核心还是字节码
>   * 语言无关性可以让其他语言如`kotlin`运行在JVM上
>   * 核心是不同语言对应的不同的编译器将源代码编译成统一的`class`字节码格式
> * 强大的字节码
>   * `java`所有的语义都要在字节码层面上表示出来，代表字节码可以表达出某些`java`语言本身无法有效支持的语义
>   * 即字节码比`java`语言本身要强大
>
> ### Class类文件的结构
>
> * 稳定性
>   * 自从第一版《Java虚拟机规范》发表以来，Class文件的结构定义就没有改变，只是在原有功能上进行新增
>
> * 文件与类关系
>   * 任何一个class文件类对应着唯一一个类或者接口的定义信息
>   * 但类或接口的定义信息不一定都得在文件里(比如可以动态生成，直接送入类加载器)
>
> * 文件结构
>   * 8字节为基础单位的二进制流
>   * 没有任何的分隔符
>   * 大端编码
>   * 两种数据类型
>
>     * 无符号数
>       * 描述数字，索引引用，数量值，utf-8编码字符串
>       * 大小为u1, u2, u4, u8
>
>     * 表
>       * 由多个无符号数或者其他表组成的复合类型
>       * 整个class文件可以看作一张表
>
> ### 魔数与CLass文件版本
>
> * 魔数
>
>   * 偏移量0，占4个字节
>   * 唯一作用是确定这个文件是class文件
>     * 不用文件扩展名确定是因为不安全，扩展名可以随意修改
>   * 很多其他文件(`ELF、jepg、gif`)也使用魔数，唯一的注意就是不要这个魔数和主流重合就行(4个字节，重合可能性不大)
>
> * class版本号
>
>   * 偏移量4，占4个字节
>   * 第5和第6字节是小版本号(同一个大版本的升级)
>   * 第7和第8字节是大版本号(大版本升级)
>   * 版本号严格限制了低版本JVM无法执行高版本的class文件
>
> * 查看class文件16进制形式
>
>   ```bash
>   hexedit filename
>   ```
>
>
> ### 常量池
>
> * 前述
>
>   * 是class文件的资源仓库
>   * 是整个class文件与其他项目关联最多的数据
>   * 通常是占用class文件空间最大的项目
>   * `class`文件中第一个表类型项目
>
> * const_pool_count
>
>   * 大小 —— u2
>   * 偏移为8，大小为2
>   * 计数为1开始而不是0开始
>   * 索引为1的常量为空白，代表`不引用任何一个常量项目`
>
> * 常量池两大类常量
>
>   * 字面量 —— 接近java中常量的概念
>     * 文本字符串
>     * 声明成final的常量值
>     * ……
>   * 符号引用 —— 编译原理概念的常量
>     * 类或接口的全限定名
>     * 字段、方法的名称和描述符
>     * 方法的句柄和方法类型
>       * Java链接全在运行时进行动态链接
>     * 动态调用点和动态常量
>     * ……
>
> * 常量池结构
>
>   * 每一个常量都是一个表
>   * 表结构起始的第一位是个u1类型的tag，每个标志值代表一种常量类型
>
> * 不同类型常量结构
>
>   * 每个类型的常量都有它固定的格式
>   * 不同的常量的大小是不一样的，但一般都可以结合常量标志tag和其他信息比如length得出大小
>
> * 查看常量命令
>
>   ```shell
>   javap -verbose TestAllocation
>   ```
>
>   ```java
>      #1 = Methodref          #7.#23         // java/lang/Object."<init>":()V
>      #2 = Methodref          #3.#24         // TestAllocation.testBigObject:()V
>      #3 = Class              #25            // TestAllocation
>      #4 = Integer            2097152
>      #5 = Integer            4194304
>      #6 = Methodref          #26.#27        // java/lang/System.gc:()V
>      #7 = Class              #28            // java/lang/Object
>      #8 = Utf8               _1MB
>      #9 = Utf8               I
>     #10 = Utf8               ConstantValue
>     #11 = Integer            1048576
>     #12 = Utf8               <init>
>     #13 = Utf8               ()V
>     #14 = Utf8               Code
>     #15 = Utf8               LineNumberTable
>     #16 = Utf8               main
>     #17 = Utf8               ([Ljava/lang/String;)V
>     #18 = Utf8               testEden
>     #19 = Utf8               testBigObject
>     #20 = Utf8               gc
>     #21 = Utf8               SourceFile
>     #22 = Utf8               TestAllocation.java
>     #23 = NameAndType        #12:#13        // "<init>":()V
>     #24 = NameAndType        #19:#13        // testBigObject:()V
>     #25 = Utf8               TestAllocation
>     #26 = Class              #29            // java/lang/System
>     #27 = NameAndType        #20:#13        // gc:()V
>     #28 = Utf8               java/lang/Object
>     #29 = Utf8               java/lang/System
>   ```
>
> ### 各种名称
>
> * 全限定类名
>   * 如`java/lang/Object`
> * 简单名称
>   * 如`func`
> * 描述符
>   * 只包括参数和返回值
>   * 如`()V`、`([II)I`
>
> ### override
>
> * 字段和方法一样，只要在子类中没有进行重写，就不会有来自父类的信息
> * 因为要访问时可以通过`父类索引`来访问
>
> ### overload
>
> * 重载的核心是方法`特征签名`，即`描述符`
> * 而描述符只包括了参数和返回值，因此方法重载不以返回值来区分
>
> ### 字节码指令简介
>
> * 定义
>
>   * 字节码指令由`一个字节长度`的`操作码`以及随后的零或多个操作数构成
>
> * 特点
>
>   * 面向操作数栈而不是面向寄存器
>   * 只有一个操作码，操作参数都放在操作数栈中
>
> * 限制长度特点
>
>   * 优点
>     * 放弃对齐(当有超过一个字节的数据时)可以节省空间
>     * 编译代码更短小精悍
>     * 数据尽可能小，效率尽可能高
>   * 缺点
>     * 当处理超过一个字节的数据时会在运行时重建具体数据结构，比如 `byte1 << 8 | byte2`
>     * 损失一部分性能
>
> * 伪代码
>
>   ```java
>   do {
>       PC++;
>       load opcode;
>       if(needOperand)
>           load operand;
>       do operation;
>   }while(codeStream > 0)
>   ```
>
> ### 字节码与数据类型
>
> * 指令包含数据类型
>   * java大多数指令包含处理数据的类型，如iload
>
> * 非完全独立性
>   * 由于java一共最多255条指令(`指令长度固定1字节`)，因此不可能所有指令都包含数据类型
>   * 有一些单独的指令可以在必要时候用来将一些不支持的类型转换成支持的类型
>
> * 转化为int
>   * bool、byte、short、char全部转换成int来处理
>
> ### 指令类型
>
> * 加载和存储指令
>   * 将数据在局部变量表和操作数栈中交换
> * 运算指令
>   * 进行运算，结果存储`操作数栈顶`
> * 类型转换指令
>   * 两种不同类型之间的相互转换
> * 对象创建和访问指令
>   * 虽然类和数组都是对象，但`java`采取了不同的处理方式
>   * 指令举例：`new、newarray、……`
> * 操作数栈管理指令
> * 控制转移指令
> * 方法调用和返回指令
>   * 调用指令：`invokevirtual、invokespecail、invokeinterface、invokestatic、invokedynamic`
>   * 返回指令：`ireturn、freturn、areturn、……`
> * 异常处理指令
> * 同步指令
>   * `synchronized`语法由`monitorenter、monnitorexit`两条指令来实现
>
> ### 公有设计，私有实现
>
> * 分界线
>   * 只要私有实现后Class文件依然能够被正确读取，并且语义完整，那么就无所谓，只要它对外接口保持一致就行
>
> * 虚拟机的两种实现方式
>   * 将输入的java虚拟机代码在加载或者执行时翻译成`另一种虚拟机的指令集`
>   * 将输入的java虚拟机代码在加载或者执行时翻译成`宿主机处理程序的本地指令集`
>     * 就是即时编译JIT，通常第二种方式用得多
>
> ### class文件发展
>
> * 大体不变
>   * 那么多年class文件的基本框架从未改变
>
> * 小的改变
>   * 多年来一直只是添加属性，用于支持新出现的语法和语言特性
>
> *************************

## class文件字节码结构

> ### 简单结构
>
> | type           | name                | number                  |
> | -------------- | ------------------- | ----------------------- |
> | u4             | magic               | 1                       |
> | u2             | minor_version       | 1                       |
> | u2             | major_version       | 1                       |
> | u2             | constant_pool_count | 1                       |
> | cp_info        | constant_pool       | constant_pool_count - 1 |
> | u2             | access_flags        | 1                       |
> | u2             | super_class         | 1                       |
> | u2             | interface_count     | 1                       |
> | u2             | interfaces          | interface_count         |
> | u2             | fields_count        | 1                       |
> | field_info     | fields              | fields_count            |
> | u2             | methods_count       | 1                       |
> | method_info    | methods             | methods_count           |
> | u2             | attributes_count    | 1                       |
> | attribute_info | attributes          | attributes_count        |
>
> ### 详细结构
>
> * 魔数 —— 4字节表示是class文件
>
> * 版本 —— 4字节表示此class文件的版本
>
> * 常量池 —— 分为字面量和符号引用(编译方面概念而非对象引用概念)。字面量包括如字符串，final型变量等；符号引用包括如包名、全限定类名、字段名称和描述符等
>
>   * 常量池容器计数器 —— 表示常量池的常量个数
>
>   * CONSTANT_Utf8_info —— 表示字符串字面量
>
>     | 类型 | 名称                    | 数量   |
>     | ---- | ----------------------- | ------ |
>     | u1   | tag - 标志位区分类型    | 1      |
>     | u2   | length - u2规定最大长度 | 1      |
>     | u1   | bytes                   | length |
>
>   * CONSTANT_Class_info —— 类或接口的全限定名
>
>     | 类型 | 名称                      | 数量 |
>     | ---- | ------------------------- | ---- |
>     | u1   | tag                       | 1    |
>     | u2   | name_index - 常量池索引值 | 1    |
>
>   * CONSTANT_Integer/Float/Long/Double_info
>
>     | 类型  | 名称  | 数量 |
>     | ----- | ----- | ---- |
>     | u1    | tag   | 1    |
>     | u4/u8 | bytes | 1    |
>
>   * CONSTANT_String_info
>
>     | 类型 | 名称                     | 数量 |
>     | ---- | ------------------------ | ---- |
>     | u1   | tag                      | 1    |
>     | u2   | index - 字符串字面量索引 | 1    |
>
>   * CONSTANT_Fieldref/InterfaceMethodref_info
>
>     | 类型 | 名称                          | 数量 |
>     | ---- | ----------------------------- | ---- |
>     | u1   | tag                           | 1    |
>     | u2   | index - Class_info类名索引    | 1    |
>     | u2   | index - NameAndType描述符索引 | 1    |
>
>   * CONSTANT_NameAndType_info
>
>     | 类型 | 名称                   | 数量 |
>     | ---- | ---------------------- | ---- |
>     | u1   | tag                    | 1    |
>     | u2   | index - 名称常量索引   | 1    |
>     | u2   | index - 描述符常量索引 | 1    |
>
>   * ……
>
> * 访问标志 —— 2字节`u2`一共16位，每一位表示一个关键字。如`public、abstract、final、annotation`
>
> * 类索引 —— 2字节`u2`表示类索引，指向一个`CONSTANT_Class_info`类型常量，表示类全限定类名
>
> * 父类索引 —— 2字节`u2`表示父类索引，指向一个`CONSTANT_Class_info`类型常量，表示父类全限定类名
>
> * 接口索引
>
>   * 2字节`u2`表示接口数量`count`
>   * `count`个接口的索引，每个指向常量池中的一个常量，表示全限定接口名
>
> * 字段表集合 —— 用于描述接口和类中声明的变量
>
>   * 字段表计数器 —— u2`表示有`count`个字段
>   * `count`个字段
>     * access_flags —— u2，每一位表示一个关键字
>     * name_index —— u2，字段的`简单名称`(没有类型和参数修饰的方法或字段名称，如`myAge`)索引
>     * descriptor_index —— u2，描述字段`数据类型`。如`[[java/ang/String`表示二维字符串数组
>     * 属性表集合(可选，不是每个字段都有)
>       * attribute_count —— u2属性表计数器
>       * attribute_info —— 数量为`attribute_count`
>
> * 方法表集合 —— 和字段表几乎一致
>
>   * 方法表计数器 ——  u2`表示有`count`个方法
> * `count`个方法
>     * access_flags —— 2字节16位访问符，每一位表示一个关键字
>   * name_index —— 方法的简单名称(没有类型和参数修饰的方法名称，如‘add’)索引
>     * descriptor_index —— 描述方法参数列表，返回值。如'([CII[CIII)I'
>   * 属性表集合
>       * attribute_count —— u2属性表计数器
>     * attribute_info —— 数量为`attribute_count`
>
> ### 属性表
>
> * 每一个属性表结构
>
>   | 类型 | 名称                                    | 数量             |
>   | ---- | --------------------------------------- | ---------------- |
>   | u2   | attribute_name_index - `UTF8字面量索引` | 1                |
>   | u4   | attribute_length - `整个属性长度 - 6`   | 1                |
>   | u1   | info - `各个属性值`                     | attribute_length |
>
> * 属性举例
>
>   * code属性
>
>     * 属性表结构
>
>       | 类型           | 名称                   | 数量                   |
>       | -------------- | ---------------------- | ---------------------- |
>       | u2             | attribute_name_index   | 1                      |
>       | u4             | attribute_length       | 1                      |
>       | u2             | max_stack              | 1                      |
>       | u2             | max_locals             | 1                      |
>       | u4             | code_length            | 1                      |
>       | u1             | code                   | code_length            |
>       | u2             | exception_table_length | 1                      |
>       | exception_info | exception_table        | exception_table_length |
>       | u2             | attribute_count        | 1                      |
>       | attribute_info | attibutes              | attribute_count        |
>
>     * 每一项含义
>
>       * `max_stack`	
>
>         * 代表操作数栈最大深度
>         * 编译生成字节码时可知
>         * 分配栈帧时就用这个属性
>
>       * `max_locals`
>
>         * 局部变量表空间大小
>         * 编译生成字节码时可知
>         * 单位是`变量槽`
>         * 普通成员方法此值不为零，因为要隐式传递`this`引用·
>
>       * `exception_table` 
>
>         * code属性内非必须，代表try-catch
>
>         | 类型 | 名称                                 | 数量 |
>         | ---- | ------------------------------------ | ---- |
>         | u2   | start_pc - 起始地址                  | 1    |
>         | u2   | end_pc - 终止地址                    | 1    |
>         | u2   | handler_pc - 什么地方处理            | 1    |
>         | u2   | catch_type - Class索引，什么类型异常 | 1    |
>
>   * Exception属性 —— 代表throw
>
>     | 类型 | 名称                                            | 数量                |
>     | ---- | ----------------------------------------------- | ------------------- |
>     | u2   | attribute_name_index                            | 1                   |
>     | u4   | attribute_length                                | 1                   |
>     | u2   | numbers_of_exceptions                           | 1                   |
>     | u2   | exception_index_table - Class索引，什么类型异常 | number_of_exception |
>
>   * LineNumberTable
>
>     * 非必须
>     * 用于描述java源码与行号关系
>
>   * LocalVariableTable
>
>     * 非必须
>     * 描述栈帧中局部变量与java源码中定义变量的关系
>     * 因为没有这项属性的话，参数的名字会消失。对于调试非常不友好
>
>   * LocalVariableTypeTable
>
>     * 和上一个几乎一样
>     * 仅仅把`descriptor_index`换成`signature`属性，用于支持泛型(因为擦除后没有类型信息了)
>
>   * SourceFIle属性 —— 用于记录生成这个Class文件的源码文件名称
>
>   * SourceDebugExtension属性 —— 方便在编译器和动态生成的Class中加入供程序员自定义的内容，新增此属性存储额外的代码调试信息
>
>   * ConstantValue属性 —— 通知虚拟机自动为静态变量赋值，只能用于`static`修饰变量
>
>     * 如果使用`final static`的话，使用此属性来初始化
>     * 如果只是`static`的话，使用`<clinit>()`方法来初始化
>
>     | 类型 | 名称                 | 数量 |
>     | ---- | -------------------- | ---- |
>     | u2   | attribute_name_index | 1    |
>     | u4   | attribute_length     | 1    |
>     | u1   | constantvalue_index  | 1    |
>
>   * InnerClass属性 —— 用于记录内部类和宿主类之间的关联
>
>   * Deprecated属性
>
>     * 是一个布尔属性，只存在有与无的区别
>     * 可以使用`@Deprecated`注解来设置
>
>   * Synthetic属性 —— 代表此字段和方法不由java源码产生，而是由编译器自动添加
>
>     | 类型 | 名称                 | 数量 |
>     | ---- | -------------------- | ---- |
>     | u2   | attribute_name_index | 1    |
>     | u4   | attribute_length     | 1    |
>
>   * StackMapTable属性
>
>     * 位于`code`属性的属性表中
>     * 在JVM类加载的`验证`阶段被类型检查器使用，用于替换之前消耗性能的基于数据流分析的类型推导验证器
>
>   * `Signature`属性
>
>     * 记录泛型签名信息
>     * 现在`反射`获取泛型类型，就是用的这个属性
>
>   * MethodParameters属性 —— 记录方法的各个形参名称和信息
>
>   * RuntimeVisiableXXXAnotation
>
>     * `XXX`表示不同的名字，一共有6个
>     * 记录类、字段、方法声明的运行时可见的注解。反射获取注解就是通过这个属性
>
>   * ……
>
> *********************************

## 第七章 虚拟机类加载机制

> ### 概述
>
> * 什么是类加载
>   * JVM把描述类的数据从class文件加载到内存，并对数据进行校验，转换解析和初始化，最终形成可以被虚拟机使用的java类型的这个过程
> * 非编译时而运行时
>   * 类型的加载，链接，初始化过程全都是在运行时完成的
>   * 没有放在编译时有一定运行时性能开销，但给Java应用提供了极高的拓展性和灵活性
> * class文件
>   * 指的是`一串二进制流`，它的来源可以是种多样
>   * 可以是磁盘文件，可以是网络二进制流，可以由数据库，可以动态生成
>
> ### 类加载时机
>
> * 一个类的生命周期
>   * 加载
>   * 验证
>   * 准备
>   * 解析
>   * 初始化
>   * 使用
>   * 卸载
>  * 其中`类加载`过程即前面生命周期的前`5`个过程
> * 各个步骤时机
>   * 解析前后的5个阶段顺序是固定的，但`解析`的时机不一定，可以在初始化阶段后再进行，因为这样可以实现`动态绑定`
>   * 第一步`加载`什么时候进行也没有规定，可以由JVM自己实现
>   * 但第5步`初始化`有且仅有六种情况才能做
>
> ### 加载
>
> * 概念
>   * `加载`阶段是`类加载`过程中的一个阶段
> * 三件事情
>   * 通过一个类的全限定类名获取定义此类的二进制字节流
>   * 将这个字节流所代表的静态存储结构转换为方法区运行时数据结构
>   * 在内存中生成一个`java.lang.Class`对象，作为方法区这个类的各种数据访问入口
> * 获取二进制流
>   * 没规定一定从磁盘获取，因此就这一点空隙就诞生了许多举足轻重的技术
>   * 从压缩包获取诞生了 `jar包，war包`技术
>   * 从网络获取诞生`web applet`技术
>   * 运行时计算生成诞生`动态代理`技术，即使用`ProxyGenerateProxyClass()`来为接口生成`$Proxy`的代理类二进制流
>   * 从加密文件中或许，诞生了`防反编译加密`技术
> * 数组类加载
>   * 和普通类加载有区别，但也有联系
>   * 数组类由JVM直接在内存中构建
>   * 数组类的元素类型如果是引用类型就和上面加载普通类一样，如果是基本数据类型JVM就会把数组标记为与引导类加载器关联
> * 结果
>   * 外部二进制字节流按照规定格式存储在`方法区`
>   * 堆内存中的`java.lang.Class`对象作为程序访问方法区中类型数据的外部接口
>
> ### 验证
>
> * 作用
>   * 确保class文件中的字节流中包含的信息全部符合《Java虚拟机规范》的约束，保证这些信息被当成代码后不会危害虚拟机自身安全
> * 原因
>   * Java语言是相对安全的
>   * `class`文件二进制流可以从任何地方或许。如何保证它的安全性不会危害程序？
>   * 使用`验证`
> * 所占时间
>   * 验证所占用时间在整个类加载过程中其实比较长
> * 验证内容
>   * 文件格式验证
>     * 内容
>       * 验证字节流是否符合Class文件格式的规范，并且能够被当前版本的虚拟机执行
>       * 如：`魔数、版本是否复合、常量池类型是否正确、……`
>     * 目的
>       * 保证输入的字节流能够被正确的解析并存储于方法区内，格式上复合描述一个Java类型信息的要求
>     * 结果
>       * 这个阶段是基于二进制流的，后续的所有验证就是基于方法区存储的结构了，不会基于二进制流
>   * 元数据验证
>     * 对字节码描述的信息进行语义分析，保证其符合java语言规范
>     * 如：`是否有父类、是否继承了final、是否实现所有方法……`
>   * 字节码验证
>     * 概述
>       * 是验证过程中最复杂的一个阶段
>     * 目的
>       * 确定程序语义是否合法，合逻辑
>       * 对方法体的`code`属性进行校验分析
>     * 内容
>       * 保证操作数栈的数据类型和指令代码能配合
>       * 保证类型转换是有效的
>       * ……
>     * 两种方式
>       * 运行时数据流分析、控制流分析
>         * 复杂性高，但更安全
>       * `javac`编译时分析，运行时验证
>         * 通过编译时进行分析，把结果存储在`code`属性的`StackMapTable`属性内
>         * 运行时压力小，但可能直接修改`class`的`StackMapTable`属性
>     * 同过数据流和控制流分析，分析程序语义是否合法、符合逻辑
>     * 会用到code属性表的StackMapTable属性。即把验证放到编译时去做，节省运行时的验证时间
>   * 符号引用验证
>     * 对类自身以外的各类信息进行匹配性校验，通俗来说就是该类是否缺少或者禁止访问它依赖的某些外部类、方法、字段等资源
> * 最后
>   * 验证阶段很费时，但却非常重要
>   * 如果保证验证无问题，可以使用`-Xverify:none`来关闭大部分的验证措施，来减少运行时验证的开销
>
> ### 准备
>
> * 作用
>   * 为类定义的变量(静态变量)分配内存并设置初始值
> * 分配位置
>   * 方法区。但方法区是一个`接口概念`，它真正的实现在`jdk8`之后都放在堆内存上了
> * 赋值
>   * 概念
>     * 此处的赋初始值是赋`初始零`值，即全部赋`零`
>   * 传统概念的赋值
>     * 那个赋值一般指的是执行`<clinit>()`方法，和这个的准备阶段赋值还有点不一样
>   * 例外
>     * 如果类字段的属性表中有`ConstantValue`属性，则准备阶段使用属性所指定的值来进行初始化
>
> ### 解析
>
> * 作用
>
>   * JVM将常量池内的符号引用替换为直接引用的过程
>   * 相当于`C++`里面链接中的`重定位`
> * 两个概念
>   * 符号引用
>     * 以一组符号来描述所引用的目标
>     * 符号可以是任何形式的字面量，只要能唯一定位目标即可
>     * 与内存位置无关
>
>   * 直接引用
>     * 可以直接指向目标的指针、相对偏移量或者能够间接定位的句柄
>     * 与内存相关，能直接定位到其内存值
> * 解析时间
>
>   * JVM规范未作具体规定
>   * 只要求17个用于操作符号引用之前必须进行对应的解析
> * 解析缓存
>
>   * 适用于对同一个符号引用的多次解析
>   * 但`invokedynamic`指令例外，它必须运行到这一条指令时才进行解析
> * 主要解析类型
>
>   * CONSTANT_Class_info
>   * CONSTANT_Fieldref_info
>   * CONSTANT_Methodref_info
>   * CONSTANT_InterfaceMethodref_info
>   * CONSTANT_MethodType_info
>   * CONSTANT_MethodHandle_info
>   * CONSTANT_Dynamic_info
> * 解析背景
>   * 假设当前代码处于`类D`，需要把`符号引用N`解析成一个目标直接引用
> * 类或接口解析
>
>   * 如果`C`不是一个数组，则JVM把`N`代表的全限定类名传递给`D`的类加载器去加载
>   * 如果`C`是一个数组，并且数组元素类型为引用(即非基础数据类型)，则和第一条过程类似
>   * 最后确定是否有访问权限
> * 字段解析
>   * 首先解析`N`中`class_index`索引指代的类或者接口，如果成功，则把这个字段所属的类或接口用`C`表示
>   * 如果`C`中本来就包含了`N`中`简单名称和描述符`相匹配的字段，则查找成功。否则进行下一条
>   * 按照实现关系递归搜索父接口
>   * 按照继承关系递归搜索父类
>   * 如果成功最后做访问权限验证
> * 非接口类方法解析
>   * 和字段解析几乎一样
> * 接口方法解析
>   * 和字段解析几乎一样
>
> ### 初始化
>
> * 概念
>   * 是类加载机制的最后一个阶段
> * 控制权交替
>   * 加载阶段用户可以自定义类加载器来获取`class 二进制流`，这时控制权在用户
>   * 后续的到初始化前的过程全部由`JVM`控制，用户无法掌控
>   * 到了初始化阶段控制权又交给了应用程序
> * 背景
>   * 在准备阶段已经给类变量赋了一次`零值`了
> * 作用
>   * 执行类构造器`<clinit>()`方法
> * `<clinit>()方法`
>   * 不是在java源代码中编写，而是`javac`自动生成
>   * 由·javac·自动收集类中所有`类变量的赋值动作`和`静态语句块(static{})`中的语句合并产生
>   * `javac`收集顺序由语句在源文件中出现的顺序决定
>   * 对于`static{}`块后定义的变量，此`static{}`只能进行赋值但是不能访问
> * `<clinit>()`方法执行顺序
>   * 并不一定子类执行前显示地调用父类的`<clinit>()`方法执行
>   * 只用保证父类的已经执行过就可以了
>   * 因此java首先肯定执行`java.lang.Object.clinit()`方法
>   * 由上得父类的静态语句块执行优先级比子类高，因此子类可以覆盖修改父类的静态值
> * 接口
>   * 接口不能使用静态语句块，但编译器仍然会生成`<clinit>()`方法
> * 同步性
>   * `<clinit>()`方法只会执行一次，因此要保证多线程同时加载一个类的并发情况
>   * 解决方式是`<clinit>()`方法全程加锁，同时访问则其他线程必须等待
>   * 如果`<clinit>()`方法执行时间过长，可能会造成线程阻塞
>
> ### 类加载器
>
> * 作用
>   * 通过一个类的全限定类名来获取描述该类的二进制字节流
>
> * 特点
>   * 此过程是在JVM外部实现的
>   * 使用Java可以玩出花来，如`OSGi、程序热部署、……`
>
> ### 类与类加载器
>
> * 类的唯一性
>   * 当讨论java程序中两个类是否相同时，只有在加载这两个类的类加载器相同时才有讨论的可能
>   * 即使类来自同一个class源文件，但类加载器不同，在java中它们依然是不同的类
>
> ### 双亲委派机制
>
> * Java虚拟机角度只有两类类加载器
>   * `Bootstrap ClassLoade`
>     * 由`C++`编写实现
>     * 是虚拟机本身的一部分
>   * 其他类加载器
>     * 由`java`语言实现
>     * 独立于虚拟机外部
>     * 全部继承子抽象类`java.lang.ClassLoader`
> * 三层类加载器
>   * Bootstrap ClassLoader
>     * 加载目录
>       * <JAVA_HOME>\lib
>       * 被 -Xbootstrappath指定的路径，且能被JVM识别的类
>     * 加载失败情况
>       * 委派给Extension ClassLoader进行加载
>   * Extension ClassLoader
>     * 加载目录 - <JAVA_HOME>\lib\ext
>     * 目的 - 允许用户将具有通用性的类库放在这个拓展java SE的功能
>   * Application ClassLoader
>     * 加载目录 - 用户类路径ClassPath
> * 双亲委托机制
>   * 要求除了顶层的类加载器外，其余的类都应该有自己的`父类`。这里的父类不是使用的`继承`关系，而是使用`组合`复用技术
>   * 过程
>     * 一个类加载器收到加载请求，首先它不会尝试去加载这个类，而是把这个加载请求委托给它的`父类`
>     * 因此所有加载请求都会被送到`Bootstrap ClassLoader`
>     * 只有当父类反馈自己无法加载这个类时(搜索范围内找不到需要的类)，子加载器才会尝试自己去加载
> * 好处
>   * 使java中的类随着类加载器具备了一种带有优先级的层次关系
>   * 得益于这套机制，`java.lang.Object`肯定被`Bootstrap ClassLoader`加载。能够保证`Object`在多类加载器的环境中是同一个类
> * 实现
>   * 在`loadClass`方法中实现，只有短短的`10`行代码
> * 总结特点
>   * 即使使用底层自定义的类加载器，越基础的类还是越由顶层的类加载器进行加载
> * 注意
>   * 以上所有只针对JDK9之前
>
> ### java模块化系统 - JPMS
>
> * 引入时间
>   * JDK9及以后
>
> * 关键目标
>   * 可配置的封装隔离机制
>
> * 模块定义
>   * 不仅仅是之前jar包仅仅充当代码的容器
>   * 依赖其他模块的列表
>   * 导出的包的列表
>   * 开放的包的列表
>   * 使用的服务列表
>   * 提供服务的实现列表
>
> * 结果
>   * 由于模块可以直接显示声明对其他模块的依赖
>   * 之前如果类缺失只有到了类加载的resolution阶段才报错
>   * 现在直接在启动检查模块时就能及时报错
>   * 模块化还可以限制public权限，将权限管理进一步细分
>
> ### 模块化的兼容性
>
> * 诞生原因
>   * 为了兼容JDK9之前的类路径查找加载机制
>
> * 解决方案
>   * 提出ClassPath和ModulePath两个概念
>   * jar包只要被放在ClassPath下，即使有module-info.class文件也是普通jar包
>   * jar包只要被放在ModulePath下，即使无module-info.class文件也是模块
>
> * 兼容规则
>   * 模块jar在类路径下被自动打包成unnamed模块，完全透明使用其他所有地方的包
>   * 普通jar在模块路径下被自动打包成automatic模块，默认依赖其他所有模块(因此可以访问其他所有模块)，导出的包也是任何模块都能访问
>   * 模块jar在模块路径下看不到匿名模块(即看不到类路径)
>
> * 缺点
>   * 由于IBM OSGi的存在，JPMS不支持热部署，热交换，同模块多版本控制
>
> ### 模块化下的类加载器
>
> * 总体变化
>   * 增加了模块化结构后并没有对java持续了20年的双亲委派机制发生根本破坏
>   * 只是兼容以前的双亲委派机制并增加了新的支持模块化的委派机制
>
> * 改变
>   * Extension ClassLoader 被 Platform ClassLoader取代
>
> * 模块化委派
>   * 当Platform ClassLoader和Application ClassLoader需要委派的父类时
>   * 之前的委派机制会直接委派给父类进行类加载
>   * 但现在要先判断此类是否属于某一个系统模块
>   * 如果属于某个系统模块，就交给负责这个模块的类加载器进行加载
>
> ***

## 第八章 虚拟机字节码执行引擎

> ### 概述
>
> * 与物理机执行引擎的区别
>   * 物理机执行引擎直接依赖于物理机的处理器、缓存、指令集、操作系统
>   * 虚拟机执行引擎是`软件自由实现`的，能不受物理机限制，定制自己的指令集与执行引擎的结构体系，还能执行那些不被物理机直接支持的指令集格式
>
> * 虚拟机执行引擎执行方式
>   * 解释执行 —— 通过解释器执行
>   * 编译执行 —— 通过编译器产生本地代码执行
>
> * JVM统一性 —— 概念一致性
>   * 无论那种JVM实现，采取那种执行方式
>   * JVM都是输入字节码二进制流，输出执行结果
>
> * 概念层面
>   * 鉴于JVM只保证对外暴露的接口相同，其内字节码二进制流究竟如何执行不同虚拟机如何执行是很可能不同的
>   * 因此只讨论概念层面的执行引擎
>   * 至于实际的JVM如何执行，如果加上各种优化更可能与概念层面的执行出入很大
>
> ### 运行时栈帧结构
>
> * 栈帧存储内容
>   * 局部变量表
>   * 操作数栈
>   * 动态链接
>   * 返回地址
>   * 额外信息
>
> * 栈帧大小
>   * 操作数栈深度 - `max_stack`确定
>   * 局部变量表槽数 - `max_local`确定
>   * 栈帧不受运行时影响，仅仅取决于程序源码和具体虚拟机实现栈内存的布局形式
>
> ### 局部变量表
>
> * 最小单位
>   * 变量槽(大小一般为32位)
> * 存储类型
>   * char
>   * boolean
>   * short
>   * int
>   * long - 两个变量槽
>   * float
>   * double - 两个变量槽
>   * reference
>   * returnAddress
> * reference类型
>   * 作用
>     * 根据引用直接或间接地 查找到对象在java堆中的数据存放起始地址或索引
>     * 根据引用直接或间接地查找到对象所属类型在方法区存储的类型信息
>   * 第二个作用是java能够实现反射的根本
> * 访问
>   * 局部变量表是线程私有的，因此不存在多线程并发访问的问题
>   * 64位数据占据两个局部变量槽，但不允许单独访问其中一个变量槽，必须整体访问，否则类加载的`验证`阶段抛异常
> * 作用
>   * 参数传递
>     * 变量槽0永远都是代表本对象的`引用指针this`
>   * 局部变量分配
> * 垃圾收集影响
>   * 当一个变量无引用时，它很可能并不会被GC收集
>   * 因为相对于有引用时局部变量表没有发生任何改变，仍然有reference指向堆里面的变量
>   * 但是增加一条 `int a = 1;`或者`obj == null;`时就能回收
>   * 因为赋值语句覆盖了之前局部变量表的引用，达到了释放引用的目的
>   * 因此之前有个编程规范 —— `不使用的对象要将它赋值为null`
>   * 但此规范其实并不好，此语句经过编译优化几乎肯定是无效语句。如果是即时编译，优化方式和手段更多，肯定会被干掉
> * 初始值
>   * 局部变量表的变量不像类变量
>   * 类变量在准备阶段就会赋`初始值零值`，但局部变量表不会
>   * 因此局部变量必须赋值后使用
>
> ### 操作数栈
>
> * 概念
>   * 栈单位
>     * 一个栈单位是32位
>     * long和double类型占两个栈单位
>   * 栈大小
>     * 由`max_stack`决定
>     * `javac`的数据流分析工作保证栈最深都不会超过这个栈深度
> * 操作
>   * 字节码指令会往操作数栈中写入和提取内容
>   * 举例：`iadd`指令将栈顶的两个`int`变量出栈，将它们相加，最后再将相加的结果入栈
> * 操作类型匹配
>   * 基于栈的字节码指令常常是不带参数的
>   * 因此栈顶元素的类型必须和当前指令所能处理的类型一致
>   * `javac和校验阶段`的数据流阶段都会保证这一点
>
> ### 动态链接
>
> * 定义
>   * 每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用的目的是为了支持方法调用过程中的`动态链接`
>
> * 调用参数
>   * class文件的常量池中存放着大量的符号引用，字节码的调用指令就是以class文件常量池里的方法符号引用作为参数的
> * 静态解析
>   * 在类加载阶段将符号引用转换为直接引用
> * 动态链接
>   * 在每一次运行时才转化为直接引用称为动态链接
>
> ### 方法返回地址
>
> * 方法两种退出方式
>   * 遇到方法调用返回指令
>   * 遇到异常但没有正确处理异常
>
> * 出栈操作
>   * 恢复上层调用方法的局部变量表和操作数栈
>   * 把返回值压入调用方法的操作数栈中
>   * 调整PC计数器的值，指向方法调用的后一条指令
>
> ### 方法调用
>
> * 唯一任务
>   * 确定被调用方法的版本
>
> * 编译无链接
>   * class文件存储的都是符号引用，而不是方法在实际运行时内存布局的入口地址
>   * 这个特性给了java极强的动态拓展能力
>
> ### 解析
>
> * 定义
>   * 确定`编译器可知，运行时不变`的方法的调用版本
>   * 即在编译阶段就能知道调用方法的版本
>
> * 函数调用指令
>   * invokestatic —— 静态方法
>   * invokespecial —— 实例构造器`<init>()`，私有方法，父类中方法
>   * invokevirtual —— 虚方法
>   * invokeinference —— 接口方法，会在运行时确定一个实现该接口的对象
>   * invokedynamic —— 先在运行时动态解析出调用点限定符所引用的方法， 然后再执行该方法
>     * 前面四种调用指令的分派逻辑都`固化在虚拟机内部`
>     * 而此指令的分派逻辑是由用户设定的引导方法来决定的、
>
> * 非虚方法，即`解析`的方法
>   * 静态方法
>   * 实例构造器`<init>()`
>   * 私有方法
>   * 父类中的方法
>   * final方法
>
> * 虚方法
>   * 除了非虚方法的方法
>
> * 解析特点
>   * 在编译时确定好调用的符号引用
>   * 在类加载的解析阶段确定好直接引用
>   * 不用延迟到运行时去完成符号引用到直接引用的转换
>
> ### 静态分配
>
> * 定义
>
>   * 所有依赖`静态类型`来决定方法执行版本的分派动作都称为静态分派。最典型的是`方法重载`
>
> * 与解析的区别
>
>   * 解析指的是类加载时把符号引用转换为直接引用
>   * 静态分派则是从另一个维度，从由什么类型(静态还是动态)决定方法版本来做区分
>
> * 注意
>
>   * 静态方法和构造方法不能被声明为抽象方法
>
> * 语句
>
>   ```java
>   public class StaticDispatch {
>       static abstract class Human {}
>       static class Man extends Human {}
>       static class Woman extends Human {}
>
>       public void sayHello(Human man) {
>           System.out.println("Human says hello");
>       }
>       public void sayHello(Man man) {
>           System.out.println("Man says hello");
>       }
>       public void sayHello(Womman man) {
>           System.out.println("Woman says hello");
>       }
>
>       public static void main(String[] args) {
>           Human man = new Human();
>           Human woman = new Woman();
>           StaticDispathc sd = new StaticDispatch();
>
>           sd.sayHello(man);
>           sd.sayHello(woman);
>       }
>   }
>
>   //输出结果
>   Human says hello
>   Human says hello
>   ```
>
> * 静态类型与运行时类型
>
>   * 上面`Human`称为静态类型，在编译期就可以知道
>   * 上面`Woman`称为动态类型，在编译期不可知，在运行时才可知
>
>   * 方法的`重载Overload`是根据静态类型来进行分派的
>   * 因此无论实际类型是什么，都会执行Human的方法版本
>
> * 选择时机
>
>   * 发生在编译阶段即`javac`时就确定，不由虚拟机来进行选择
>
> * 字节码执行指令
>
>   * 非`invokevirtual`
>
> * 重载的优先级
>
>   ```java
>   public static void sayHello(Object args);
>   public static void sayHello(int args);
>   public static void sayHello(long args);
>   public static void sayHello(Character args);
>   public static void sayHello(char args);
>   public static void sayHello(char... args);
>   public static void sayHello(Serializable args);
>
>   public static void main(String[] args){
>       sayHello('a');
>   }
>   ```
>
>   * 首先执行 `(char args)`
>   * 然后`(int args)`。发生一次隐式类型转换
>   * 接着`(long args)`。发生两次隐式类型转换
>   * 在然后`(Character args) `。发生一次装箱
>   * 在接着`(Sirializable args)`。在接口中找方法
>   * 后再`(Object args)`。在父类中找
>
> * 特点
>
>   * 由传入参数的类型决定实际调用方法的版本
>
> ### 动态分配
>
> * 定义
>
>   * 在运行期根据实际类型确定方法执行版本的分派过程叫作`动态分派`
>
> * `invokevirtual`指令执行过程
>
>   * 找到操作数栈顶的元素所指向对象的实际类型，记为C
>   * 在C中找是否有`描述符和简单名称`都相同的方法，如果有就进行权限检验。检验失败就报异常，检验成功就返回这个直接引用
>   * 否则按照继承关系查找
>   * 最后都没查找到就报`java.lang.AbstractMethodError`异常
>   * 即在运行时检查接收者的类型，根据接收者的类型来选择实际调用版本
>
> * 字段无性多态
>
>   * 因为`invokevirtual`指令不能作用于字段
>
> * 代码
>
>   ```java
>   public class FieldHasNoVirtual {
>       static class Father{
>           public int money=1;
>           public Father(){
>               this.money=2;
>               showMoney();
>           }
>           public void showMoney(){
>               System.out.println("father has "+this.money);
>           }
>       }
>
>       static class Son extends Father{
>           public int money=3;
>           public Son(){
>               this.money=4;
>               showMoney();
>           }
>           public void showMoney(){
>               System.out.println("son has "+this.money);
>           }
>       }
>
>       public static void test() {
>           Father guy = new Son();
>           System.out.println(guy.money);
>       }
>   }
>
>   /*
>     son has 0
>     son has 4
>     2
>   */
>   ```
>
> * 分析
>
>   * `son has 0`
>     * 当执行`new Son()`时`invokespecia`l指令执行实例构造器`Son.<init>()`
>     * `Son.<init?()`方法中执行`invokespecial`指令执行父类实例构造器`Father.<init>()`
>     * `Father.<init>()`方法中执行`invokevirtual`指令执行`Father.showMoney()`
>     * 根据动态分派`invokevirtual`选择`Son.showMoney()`方法版本
>     * 因为`Son`还没初始化，因此`money`为0
>   * `son has 4`
>     * 执行完`Father.<init>()`后，执行`Son.<init>()`
>     * 然后`invokevirtual`执行`showMoney()`
>   * 2
>     * 直接执行`getfield`指令取`Father.monney`
>     * 因此是`father`的2
>
> ### 分派Dispatch总结
>
> * 静态
>   * 在编译时根据静态类型确定调用的方法版本
>
> * 动态
>   * 对于`invokevirtual`指令就动态链接
>   * 字段永远都是静态分配，只看静态类型
>
> * 各个指令执行不同的方法
>   * `invokestatic` - 静态方法
>   * `invokespecial` - 实例构造器，父类方法，私有方法。(因此showMoney()是动态的)
>
> ### 单分派与多分配
>
> * 宗量
>   * 方法的参数
>   * 方法的接收者
>
> * 多分派
>   * 单分派 —— 宗量为1
>   * 多分配 —— 宗量大于1
>
> * java分派模型
>   * 静态多分派
>   * 动态单分派
>
> * `var`与`dynamic`
>   * `var`是在编译时根据声明语句中赋值符号右边表达式类型来静态地推断类型，本质是一种`语法糖`
>   * 而`dynamic`则是编译时根本不关心类型是什么，等到运行时再进行类型推断
>
> ### JVM动态分配实现
>
> * 优化
>   * 动态分派非常频繁
>   * 不可能每次都去查，很耗时间
>   * 因此每个类都有一张虚方法表
>   * 表项存放方法的入口地址
>   * 如果子类重写了方法就替换入口地址
> * 虚方法表创建时期
>   * `准备阶段`过后
>
> ### 动态类型语言
>
> * 定义
>
>   * 类型检查的主体过程在运行时而不是在编译时
>
> * 举例
>
>   ```java
>   obj.println();
>   ```
>
>   * 假设`obj`的静态类型是`java.io.PrintStream`
>   * 那么即使`obj`的实际类型有`println()`方法但不是`PrintStream`的实现类就依然类型检查不合法
>   * 然而动态类型语言就可以
>
> * 上例原因
>
>   * 编译时已经根据静态类型生成了 `invokevirtual CONSTANT_InterfaceMethodref_info`字节码指令
>   * 即完整的符号引用已经生成，这是不能变的
>   * 这个符号引用包含了方法定义在那个具体类型中，方法名字，方法参数顺序，参数类型和方法返回值等信息
>
> * 动态语言特点
>
>   * `变量无类型而变量的值值才有类型`
>   * 编译时最多只能确定方法的名称，参数，返回值等信息
>   * 编译时不会去确定方法所有的具体类型，即方法的接收者是不固定的
>
> * 优缺点
>
>   * 静态类型语言更严谨
>   * 动态类型语言更简便
>
> ### java与动态类型
>
> * JVM缺陷
>   * 4条字节码方法执行指令在编译时就已经确定了方法的`符号引用`，等于编译时确定了方法的接收者类型
>   * 而动态语言要求运行时决定方法的接收者
> * 强行曲线救国在`4`条字节码方法指令情况下支持动态语言有很多缺点
>   * 用占位符，缓存等手段开销巨大，复杂度升高
> * `MethodHandle`与`Reflection`
>   * 两者都是模拟方法调用
>   * MethodHandle是模拟字节码层面的方法调用；Reflection是模拟java代码层面的方法调用
>   * Reflection是重量级；MethodHandle是轻量级
>   * Reflection只能为java服务；MethodHandle能为所有运行在JVM上的语言服务
>
> ### invokedynamic指令
>
> * 目的
>   * 原来4条指令的分派规则完全固化在虚拟机内部，如何把查找方法的决定权从虚拟机转接到用户手中，让用户有更高的自由度就是`invokedynamic`的目的
> * 参数变化
>   * 原来4条指令的参数是`CONSTANT_Methodref_info`
>   * 现在是`CONSTANT_InvokeDynamic_info`
>     * 引导方法`Bootstrap Method`
>     * 方法类型`Method Type`
>     * 名称
> * 执行过程
>   * 引导方法有固定名称，返回值规定是`java.lang.invoke.CallSite`对象，此对象代表了真正要执行目标方法的引用
>   * 根据`CONSTANT_InvokeDynamic_info`提供的信息，JVM找到并且执行引导方法，从而获得一个`CallSite`对象，然后引导到最终要执行的方法上面去
> * 好处
>   * `lambda`表达式和`接口默认实现`用到了`invokedynamic`
>
> ### 解释执行
>
> * 编译执行
>   * `程序源码 -> 词法分析 -> 语法分析 -> AST -> 优化器 -> 中间代码 -> 目标代码`
> * 解释执行
>   * `程序源码 -> 词法分析 -> 语法分析 -> AST -> 指令流 -> 解释器 -> 解释执行`
> * Java语言
>   * `程序源码 -> 词法分析 -> 语法分析 -> 字节码指令流`由编译器`javac`实现，这一部分在虚拟机外部
>   * 后面部分由执行引擎实现，这是在虚拟机内部
>
> ### 基于栈和基于寄存器的指令集架构
>
> * 优点
>   * 可移植性高
>     * `ARM`处理器提供了寄存器，但用户程序不直接使用
>     * 而是由虚拟机决定将一些访问最频繁的数据(PC，栈顶缓存)等放到寄存器中获取更高的性能
>     * 这样用户程序是不直接依赖硬件的，而是通过虚拟机进行依赖
>   * 代码相对紧凑
>   * 编译器实现更简单
> * 缺点
>   * 理论上执行速度会更慢，但如果是`即时执行`输出物理机汇编指令流，那就与虚拟机采取那种指令集架构无关了
>   * 入栈出栈涉及内存操作，频繁访问内存效率较低
>
> ***

## 第九章 类加载及执行子系统的案例和实战

> ### 概述
>
> * 从`class`文件格式到执行引擎这部分里，用户程序能够直接参与的地方不多
> * 用户能直接参与的地方有两处
>   * 字节码生成
>   * 类加载器加载
> * 仅仅在这两点上，就已经能搞出很多东西了
>
> ### Tomcat：正统的类加载器结构
>
> * 要求
>   * 部署在同一个服务器的两个web项目所使用的java类库可以相互隔离
>   * 部署在同一个服务器的两个web项目所使用的java类库可以相互共享
>   * 服务器尽可能保证自己的安全不受部署的web应用的影响
> * 四个目录
>   * `tomcat`和所有`web`服务可见
>   * `tomcat`可见，所有`web`服务不可见
>   * `tomcat`不可见，所有服务可见
>   * 某`web`服务可见，其他所有`web`服务和`tomcat`不可见
> * 解决方案
>   * 设置多个`ClassPath`
>   * 每个`ClassPath下`的类库有不同的访问范围，有自己的类加载器
> * 类加载器委托结构
>   * `common`类加载器
>     * `Catalina`加载器
>     * `Sharded`加载器
>       * `WebApp`加载器
>       * `Jsp`类加载器
>
> ### OSGi灵活的类加载结构
>
> * 流传观点
>   * 学Java EE去看JBoss源码
>   * 学类加载去看OSGi源码
>
> * OSGi模块(bundle)特点
>   * 文件存储格式上还是jar格式，变化不大
>   * 一个bundle可以显示声明它所依赖的其他bundle
>   * 一个bundle可以显示声明它能导出export供其他bundle所使用的部分
>   * 所有bundle都是平级的关系，而不是传统的上下级关系
>   * 一个模块只有export的包外界才能访问，未export的包是私有的
>
> * OSGi优势
>   * 模块级的热插拔功能
>
> * 优势实现
>   * 灵活的类加载器结构
>   * OSGi的类加载器只有规则而没有固定的委派关系
>   * 如果Bundle A 依赖 Bundle B的某一部分，且B的那一部分刚好被Export，则类加载器A的加载任务委派给类加载器B
>
> * 结果与缺点
>   * 加载器之间的关系成了运行时才能确定的复杂网状结构
>   * 当两个Bundle互相依赖对方的某个package，由于类加载器的loadClass()方法是同步方法，因此会造成死锁(加载某package时锁定当前loadClass()方法，把加载委派给另一个类加载器，但另一个同样操作造成死锁)
>
> ### 字节码生成与动态代理
>
> * 概述
>   * 字节码生成不是什么高深的技术
>   * 因为我们最常用的命令`javac`就是最普通的一个字节码生成器
>     * 由`java`编写
>     * 存放在`openjdk`的目录中
> * 字节码生成举例
>   * `javac命令`
>   * `jsp`编辑器
>   * 编译时织入的AOP框架
>   * 动态代理的动态生成代理类
> * 动态代理的动态
>   * 相对于静态代理在编译时静态完整生成代理类
>   * 动态代理不在于省去编写代理类的那一点代码量
>   * 而在于在原始类和接口未知时就确定代理行为
>
> ### 动态代理
>
> * 接口IConsumer
>
>   ```java
>   public interface IConsumer {
>   	void buy();
>   }
>   ```
>
> * 实现类Consumer
>
>   ```java
>   public class Consumer implements IConsumer{
>       @Override
>       public void buy() {
>       	System.out.println("buy something");
>       }
>   }
>   ```
>
> * 实现InvocationHandle接口的代理类
>
>   ```java
>   public class ConsumerProxy implements InvocationHandler {
>       private IConsumer consumer;
>
>       public ConsumerProxy(){};
>       //构造方法传入真正被代理的对象
>       public ConsumerProxy(IConsumer consumer){
>           this.consumer=consumer;
>       }
>
>       /*
>       * @param proxy 执行newInstance时生成的代理对象
>       * @param method 被代理对象的方法
>       * @param 被代理对象方法执行的参数
>       * */
>       @Override
>       public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
>           before();
>           Object returnValue = method.invoke(consumer, args);
>           after();
>           return returnValue;
>       }
>
>       private void before(){
>           System.out.println("select before buying");
>       }
>
>       private void after(){
>           System.out.println("sale return after buying");
>       }
>   }
>   ```
>
> * 执行
>
>   ```java
>   public static void main(String[] args) {
>           IConsumer consumer=(IConsumer)Proxy.newProxyInstance(
>                   Consumer.class.getClassLoader(),
>                   Consumer.class.getInterfaces(),
>                   (InvocationHandler) (Class.forName("dynamicproxy.ConsumerProxy").getConstructor(IConsumer.class).newInstance(Class.forName("dynamicproxy.Consumer").newInstance()))
>           );
>           consumer.buy();
>   }
>   ```
>
> * 核心
>   * `Proxy.newProxyInstance`会调用到磁层，会使用字节码生成技术来生成字节码
>
> ### Spring动态代理
>
> * 接口IConsumer
>
>   ```java
>   public interface IConsumer {
>       String buy(String s);
>       String saleReturn(String s);
>   }
>   ```
>
> * 实现类RichConsumer
>
>   ```java
>   @Component("richConsumer")
>   public class RichConsumer implements IConsumer{
>       @Override
>       public String buy(String s) {
>       	System.out.println("RichConsumer buy:"+s);
>       	return s;
>       }
>   
>       @Override
>       public String saleReturn(String s) {
>           System.out.println("RichConsumer sale return:"+s);
>           return s;
>       }
>   }
>   ```
>
> * 配置类`Configuration`
>
>   * 配置要扫描的包
>   * 开启动态代理
>
>   ```java
>   @Configuration
>   @ComponentScan(basePackages = {"com"})
>   @EnableAspectJAutoProxy(exposeProxy = true)
>   public class Configuration{}
>   ```
>
> * 切面类
>
>   ```java
>   @Aspect
>   @Component
>   public class ConsumerAspect {
>       @After("execution(* com.IConsumer.*(..))")
>       public void saySomething(){
>           System.out.println("穷人、富人say something");
>       }
>
>       @Before("execution(* com.IConsumer.*(..))")
>       public void saleReturn(){
>           System.out.println("I need to sale return");
>       }
>   }
>   ```
>
> * 测试
>
>   ```java
>   public static void main(String[] args) {
>           AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(Configuration.class);
>           IConsumer consumer = applicationContext.getBean("richConsumer", IConsumer.class);
>           consumer.buy("a");
>          applicationContext.getBean("poorConsumer",IConsumer.class).saleReturn("thing");
>   }
>   ```
>
>
> ### Backport工具
>
> * JDK更新内容
>   * 对Java的API类库的增强
>   * 在前端编译器做出改进(语法糖)
>   * 在字节码层面的改动(很少很少，如增加invokedynamic指令)
>   * JDK整体架构方面的改进(如java模块化系统)
>   * 虚拟机内部的改变(对程序员透明)
>
> * 逆向移植工具
>   * 作用范围：只能模拟JDK更新的前面两点
>   * 更新一：引入其他额外的库来代替新增的API库
>   * 更新二：使用字节码工具对字节码进行修改，因为指令集数量没有变化，总能使字节码表达的语义高低版本一致
>
> * Enum类本质
>   * 继承自`java.lang.Enum`
>   * 自动生成`Values()`和`ValueOf()`方法
>
> ### 实战：远程执行功能
>
> * 痛点
>
>   * 只需要在已经运行的程序中增加一小段代码就能实现bug排查，但无奈却无法实现
>
> * 思路
>
>   * 上传代码到服务器：客户端编译好后上传
>   * 如何执行编译后的代码：类加载器加载类得到Class对象，反射执行
>     * 此类要能访问到服务器端的其他类库才行
>     * 是临时代码，执行完后应被回收
>   * 如何收集结果输出：在字节码层面将执行类的System.out符号引用替换成自定义流的符号引用
>     * 不用System.out是因为其他的输出结果会一起输出过来
>
> * 类加载器实现
>
>   * 首先让自定义类加载器的上级委派设置为加载此自定义类的类加载器
>   * 类加载器公开父类的'protected Class defineClass()'方法
>   * 这样在加载自己类的时候会被委派给上级，就能访问服务端其他类库了
>   * 之所以不让服务端类加载器直接加载自定义类是因为自定义类不在类加载器的扫描范围内
>
> * 修改System.out引用
>
>   * 直接将class文件的byte[]数组进行修改
>   * 修改完成后将被修改后的byte[]数组传给自定义类加载器进行加载
>
> * 自定义流
>
>   * 将System类的静态变量out和err换成另外的流
>
> * 汇总在一起
>
>   ```java
>   HackSystem.clearBuffer();
>   ClassModifier modifier = new ClassModifier(byte[]);
>   byte[] modified = modifier.modifyConstantInfo("java/lang/System","zy/selfDefine/HackSystem");
>   Class object = new SelfDefineClassLoader.load(modified);
>   object.invoke("main",String[].class);
>   ```
>
>
> ***

## 第十章 前端编译与优化

> ### 概述
>
> > #### 前端编译器
> >
> > * 指的就是传统C编译器的前端部分
> > * 把 .java 编译成 .class
> > * 如javac
> >
> > #### 即时编译器JITC
> >
> > * 在JVM中将class字节码直接生成物理机能够执行的本地代码
> > * 如HotSpot的C1和C2编译器，Graal编译器
> >
> > #### 静态提前编译器(AOT)
> >
> > * 直接将程序代码 .java 编译成物理机能够运行的本地代码
> > * 就和gcc一模一样
> > * 如jaotc
> >
> > #### javac的程序优化
> >
> > * javac几乎无程序优化
> > * 优化放到JVM中的即时编译器进行，因为这样非java但运行在JVM上的程序依然能享受优化红利
> >
> > #### 语法糖
> >
> > * 语法糖几乎全都是靠前端编译器javac去实现的
> > * 因为最后的class字节码无论是否使用语法糖结果是一样的
> >
> > #### 总结
> >
> > * JVM的即时编译器在运行期的优化过程，支撑着程序执行效率不断提升
> > * javac前端编译器在编译期的优化过程，支撑着程序员的编码效率
> >
> > ***
>
> ### javac编译器
>
> > #### 语言实现
> >
> > * HotSpot虚拟机全部由C++(少量C)实现
> > * javac是百分之百java语言
> >
> > #### 位置
> >
> > * javac的源码就在JDK源码中
> >
> > #### 宽松的JVM规范
> >
> > * JVM对class格式做了非常详尽的约束
> > * 然而对class文件由何而来几乎没什么约束
> >
> > #### javac结构
> >
> > * 准备过程
> >   * 初始化插入式注解生成器
> > * 解析与符号填充过程
> >   * 词法、语法分析
> >   * 填充符号表 —— 产生符号信息和地址信息
> >   * 注解处理 —— 处理注解，如果处理过程生成新的符号就要重新返回填充符号表过程
> > * 语义分析过程
> >   * 标注检查 —— 对语法的静态信息进行检查
> >   * 数据流和控制流分析 —— 对程序动态运行进行检查
> >   * 解语法糖 —— 将高级的语法糖形式还原为原本的低级形式
> > * 字节码生成 —— 前面所有都完成后就可以生成最终的字节码
> >
> > ***
>
> ### 填充符号表
>
> >#### 数据结构
> >
> >* 一组符号地址和符号信息构成
> >
> >#### 使用
> >
> >* 在编译的后续阶段会使用到，如语义分析和目标代码生成
> >
> >***
>
> ### 注解处理器
>
> > #### 作用
> >
> > * 实际可以看作是一个javac插件
> > * 允许读取、修改、添加AST中的任意元素
> >
> > #### 递归过程
> >
> > * 一旦注解处理器解析出新的符号，就要返回到填充符号阶段重新处理
> >
> > #### 结果
> >
> > * 由于任意的元素甚至注释都能访问到
> > * 因此注解处理器可以提供API让程序员干涉javac的编译行为
> > * 产生了很多实用的工具如Lombok
> >
> > ***
>
> ### 语义分析
>
> > #### 语义的正确性
> >
> > * AST不能保证语义的正确性
> > * 比如 'bool b = 3;'符合AST但不符合语义
> >
> > #### 任务
> >
> > * 对结构上正确(符合AST)的程序进行上下文检查
> > * 如类型检查、控制流分析、数据流检查
> >
> > #### 过程
> >
> > * 标注检查
> > * 数据、控制流分析
> > * 解语法糖
> >
> > #### 标注检查
> >
> > * 变量使用前是否已经声明
> > * 变量赋值类型是否匹配
> > * 常量折叠优化
> >
> > #### 数据/控制流分析
> >
> > * 局部变量使用前是否已赋值
> > * 方法每条路径是否有返回值
> > * 所有异常是否都正常处理
> >
> > #### 运行期与编译期的数据流检查
> >
> > * 编译与运行期都会进行数据流检查
> > * 两者检查的目的几乎是相同的
> > * 但有些情况仅能在编译器检查或者仅能在运行期检查
> > * 比如局部变量的final符号，在运行时根本没有final符号
> >
> > #### 解语法糖
> >
> > * 将语法还原为基础的语法结构
> > * 如自动装箱、泛型、变长参数
> >
> > ***
> ### 字节码生成
>
> > #### 任务
> >
> > * 将语法树，符号表转换为字节码指令写到磁盘中
> > * 并进行少量的代码添加和转换工作
> >
> > #### 代码添加举例
> >
> > * 在填充符号阶段已经添加了默认的类构造器和实例构造器，但具体构造器的行为还没添加
> > * 字节码生成阶段将 语句块、变量初始化、调用父类构造器等操作收敛到对应的构造器中
> > * 因此在字节码阶段完成的其实是一种收敛工作
> >
> > #### 转换优化例子
> >
> > * 将字节码加法操作换成StringBuffer
> >
> > ***
>
> ### 泛型
>
> > #### 概述
> >
> > * java的泛型很垃圾
> >
> > #### 本质
> >
> > * 参数化类型和参数化多态的应用
> > * 即将操作的数据类型指定为方法签名中的一种参数
> >
> > #### C#泛型
> >
> > * Reified Generic(具现代式泛型)
> > * C#泛型无论是在编译器、中间代码生成、运行期都是真实存在的
> > * List和List<int>是两种类型
> >
> > #### java泛型
> >
> > * 仅仅在程序源代码阶段看起来是有泛型
> > * 然而在编译后就将泛型信息给擦除了，替换为裸类型
> > * 并且在相应的地方插入强制类型转换以来实现泛型的效果
> > * ArrayList<Interger> 和 ArrayList<String>其实是一个类型
> >
> > #### java泛型"优势"和劣势
> > * 优势
> >   * 只用改动编译的前端javac
> >   * 字节码、JVM都可以不用动
> >   * 保证了向后字节码兼容性
> > * 劣势
> >   * 由于在字节码层面不变，因此无法在运行时动态获取泛型的类型信息，反射获取类型做不到
> >   * 因为本质实际上强制类型转换，不停地拆箱装箱，导致效率低
> >
> > #### java选择的路
> >
> > * 直接将已有的类型原地泛型化，不添加任何平行于已有类型的泛型
> > * 而C#是直接添加了一套新的泛型类型
> >
> > #### 类型擦除
> >
> > * 为了保证老代码的兼容性，如下语句，应将泛型类型设置为裸类型的子类型
> >
> > ```java
> > ArrayList list = new ArrayList<String>; //这句不能报错，是子类型赋给裸类型
> > ```
> >
> > * 实现裸类型两种方式
> >   * 在运行期真正构造出 'ArrayList<String>' 类型，让它继承自ArrayList
> >   * 直接将 'ArrayList<String>' 还原为ArrayList，仅仅在元素访问和修改时插入强制类型转换指令
> >
> > #### 新的麻烦
> >
> > * 泛型信息擦除后，由于在运行时基本数据类型无法强制转换为Object(必须先装箱转成Integer才能转成Object)
> > * 因此java不允许 'ArrayList<int>' 存在，只允许 'ArrayList<Integer>'
> > * 运行期无法获取泛型类型信息
> > * 泛型信息被擦除可能会导致方法重载失败
> >
> > #### 注意
> >
> > * java函数的返回值属于方法签名的一部分，但返回值不参与函数重载
> >
> > #### Signature属性
> >
> > * 在code属性里擦除了泛型信息，但在Signature属性里又将泛型信息加上
> > * 因此现在可以运行时反射获取泛型类型信息了
> >
> > ***
>
> ### 自动装拆箱、遍历循环、变长参数
>
> > #### 拆装箱
> >
> > * 实际就是强制类型转换
> > * 如Integer.valueOf(), 
> >
> > #### 遍历循环
> >
> > * 实际就是使用迭代器
> > * 因此必须实现Iterable接口
> >
> > #### 自动装拆箱坏处
> >
> > * ==运算
> > * equals运算
> >
> > #### 变长参数
> >
> > * 将参数转换为一个数组
> >
> > ***
>
> ### 条件编译
>
> > #### 举例
> >
> > ```java
> > if(true) System.out.println("compile");
> > else System.out.println("not compile");
> > ```
> >
> > #### 实质
> >
> > * java的if语句如果判定条件为常数恒定值则会在编译期javac就执行
> > * 不会执行的那个分支根本不会参加编译的过程
> >
> > #### 缺点
> >
> > * 由于是用if关键字实现
> > * 因此仅限于方法块内部使用，而不能整个类条件编译
> >
> > ***
>
> ### 插入式注解器实战
>
> > #### java编译子系统用户接口
> >
> > * 即时编译的若干参数
> > * 插入式注解生成器API
> >
> > ***
>
> ***

## 第十一章 后端编译与优化

> ### 概述
>
> > #### 核心
> >
> > * 后端编译器的好坏、代码优化质量的高低是衡量JVM好坏的关键因素
> >
> > #### 后端
> >
> > * 如果把字节码看作是IR，那么任何从IR到物理机指令集二进制码的操作都可以看作是后端
> >
> > ***
>
> ### 即时编译器
>
> > #### 概述
> >
> > * 程序最开始都是解释(Interpret)执行
> > * 发现某一处代码运行特别频繁，于是定义它为热点(Hot Spot)代码
> > * 运行时编译器将热点代码直接生成本地代码，并尽可能的优化
> > * 运行时完成此任务的就是即时编译器
> >
> > ***
>
> ### 解释器与编译器
>
> > #### 两者配合
> >
> > * 程序启动时解释器可以迅速工作让程序立即运行
> > * 运行一段时间后编译器可以工作让程序运行效率提高
> > * 内存资源紧张时可以仅让解释器工作节约内存
> > * 内存资源宽松时可以多让编译器工作提升效率
> > * 解释器作为编译激进优化的逃生门(此优化大多数都能提升效率，但也会有失误的情况)
> >
> > #### 结构
> >
> > * 解释器 
> >   * Interpret解释器
> > * 编译器
> >   * 客户端编译器(C1)
> >   * 服务端编译器(C2)
> >   * Graal编译器 —— 目标是代替C2，但目前还在试验中
> >
> > #### 编译模式
> >
> > * Mixed Mode —— 解释器与编译器协同工作
> > * -XInt —— 强制只解释执行
> > * -Xcomp —— 尽量编译执行，也会有解释器参与
> >
> > #### 分层编译出现原因
> >
> > * 即时编译器要占据程序运行时间，且优化度越高，占用时间越长
> > * 解释器要替编译器收集性能控制信息，也会影响解释执行速度
> > * 为了平衡程序启动速度和执行效率，提出分层编译模型
> >
> > #### 分层编译结果
> >
> > * 解释器与编译器协同工作
> > * 热点代码多次编译，客户端获取更高的编译速度，服务端获取更高的编译质量
> > * 客户端编译器采取简单优化来为服务端编译器争取更多的编译时间
> >
> > #### 注意
> >
> > * 服务端应用不关心启动速度
> >
> > ***
>
> ### 编译对象与触发条件
>
> > #### 热点代码条件
> >
> > * 被多次调用的方法
> > * 被多次执行的循环体
> >
> > #### 编译范围
> >
> > * 无论方法还是循环体最终都会以整个方法作为编译对象
> > * 方法的入口就是方法的入口，而循环体的入口则是被编译方法的循环点入口
> > * 循环体即时编译又被称作栈上替换(On Stack Replacement)
> >
> > #### 两种热点探测技术
> >
> > * Sample Based
> > * Counter Based
> >
> > #### Sample Based
> >
> > * 周期性地检查各个线程的调用栈顶
> > * 好处是简单高效，缺点是难以精确定位
> >
> > #### Counter Based 
> >
> > * 为每个方法建立计数器
> > * 好处是精确，缺点是维护计数器麻烦
> > * HotSpot虚拟机使用Counter Based
> >
> > #### 执行方法过程
> >
> > * 首先检查是否有已编译好版本
> > * 如果有就使用本地编译后的版本，如果没有就计数器加1并查看计数器是否达到阈值
> > * 达到阈值就提交即时编译申请，然后解释执行，没达到就继续解释执行
> >
> > ***
>
> ### 编译过程
>
> > #### 默认情况
> >
> > * 所有未编译的代码都解释执行
> > * 编译进行在后台进行编译
> > * 可以设置禁止后台编译，那这样前台的执行线程就会阻塞等待编译线程
> >
> > #### 客户端编译器
> >
> > * 只做局部性优化
> > * 编译速度的权重较高，不会耗时编译高优化版本代码
> > * 放弃全局优化手段
> >
> > #### 客户端编译过程
> >
> > * class字节码转换成 High Level Intermediate Repression(机器指令无关)
> > * HIR转换成Low Level Intermediate Repression(机器指令相关)
> > * 线性扫描算法在LIR上分配寄存器，生成机器代码
> >
> > #### 服务端编译器优化
> >
> > * dead code elimination
> > * loop unrolling
> > * loop expression hoisting
> > * common subexpresion eliminatation
> > * constant propagation
> > * basic block reordering
> > * 激进优化
> > * ……
> >
> > #### 服务端对比客户端
> >
> > * 过程缓慢，优化程度高
> >
> > ***
>
> ### 编译的透明性
>
> > #### 透明
> >
> > * 无论程序使用解释执行、即时编译执行、提前编译执行
> > * 都对用户和程序员是透明的
> >
> > ***
>
> ### 提前编译
>
> > #### 历史
> >
> > * 由于提前编译与write once run everywhere理念冲突，一直没有发展
> > * 但知道Android 的ART编译器直接干掉Dalvik后，提前编译才被重视起来
> >
> > #### 缺点
> >
> > * 破坏平台中立性
> > * 字节膨胀 —— 提前编译的本地二进制代码体积大于字节码体积
> > * 动态扩展性无
> >
> > ***
>
> ### 提前编译的优劣得失
>
> > #### 两条思路
> >
> > * 像C和C++一样直接静态本地编译
> > * 作为即时编译器的缓存，当即时编译器要用时直接加载进来使用
> >
> > #### 静态本地编译
> >
> > * 直击即时编译最大缺点 —— 运行时编译占用系统资源
> > * 运行时即时编译无论怎样优化都会占用系统性能和资源
> >
> > #### 即时编译运行耗费资源举例
> >
> > * 全程序分析相当耗时，它要精确得到对生成高质量优化代码有关的信息，而得到这些信息要在全程序范围内做极耗时的计算工作
> > * 全程序分析很可能会采用激进优化，不求全部正确，有问题在回退解决
> > * ART能打败Dalvik正是因为提前编译效率高，但第一次编译太慢，安装一个应用以分钟计算。因此在后续安卓版本重新启用解释执行和即时编译，在系统空闲时在进行提前编译
> > * 大范围分析是即时编译器的劣势
> >
> > #### 即时编译缓存
> >
> > * 理论上HotSpot可以直接在运行时加载编译的结果，提升速度，但并不是那么容易
> > * 提前编译不仅与物理机绑定，还与JVM运行时参数绑定(如GC的内存屏障代码)。因此限制很大
> >
> > #### 即时编译优点
> >
> > * 性能分析制导优化
> > * 激进预测性优化 
> > * 链接时优化
> >
> > #### 性能分析制导优化
> >
> > * 即时编译运行时会收集性能监控信息
> > * 如接口通常的实现类，分支通常走那条，方法调用选那个版本
> > * 用以上信息来完成程序优化，这些是静态提前编译器而不能完成的
> >
> > #### 激进预测性优化
> >
> > * 静态提前优化必须百分百保证前后程序的接口一致性
> > * 而即时编译可以不那么严格，可以采用非常激进甚至可能出错的优化策略
> > * 反正出错了有客户端编译器或者解释器来兜底
> > * 如虚方法去虚拟化
> > * 只要概率高预测得足够准，那么性能就能提升
> >
> > #### 链接时优化
> >
> > * java运行时动态链接动态优化
> > * 然而静态编译时，主程序和链接库是分开编译分开优化的，分开优化的效果很可能不如整体动态运行时优化
> >
> > #### 总结
> >
> > * 即时编译和提前编译各有各优缺点
> >
> > ***
>
> ### 编译器优化技术
>
> > #### 概述
> >
> > * 生成本地机器码很容器
> > * 但生成高优化的优秀代码才是难点
> >
> > ***
>
> ### 方法内联
>
> > #### 重要性
> >
> > * 最重要的代码优化手段，没有之一
> > * 被称为优化之母
> > * 其一是可以降低方法调用的开销
> > * 其二是扩大优化范围，很多优化只有在内联完成后才能做
> >
> > #### java内联的困难
> >
> > * 按照经典编译理论，如果不是即时编译器做出特殊努力，java很多方法无法内联
> > * java默认的方法是虚方法，仅有少量的invokespecial指令的方法是能够在静态编译时确定方法的版本
> > * 虚方法最大的缺点就是不知道内联时去使用那个版本的方法
> > * java提倡面向对象编程，反而鼓励虚方法的使用
> > * C和C++默认的方法是静态方法，只有使用virtual关键字的方法才是虚方法
> > * java选择在虚拟机中解决虚方法的内联问题
> >
> > #### 激进的方法内联优化
> >
> > * 引入类型继承分析(Class Hierachy Analysis ) CHA
> > * 如果查询到虚方法只有一个版本，直接守护内联
> >   * 守护内联很激进，要留好逃生门
> >   * 当方法的接收者继承关系出现变化，方法有多个版本时推出守护内联
> > * 如果查询到多个版本，直接进行内联缓存
> >   * 缓存命中就相当于只有一个方法版本
> >   * 不命中就重新动态分派
> >
> > ***
>
> ### 逃逸分析
>
> > #### 性质
> >
> > * 不是一种优化的手段，而是像CHA一样为其他优化提供分析技术
> >
> > #### 逃逸
> >
> > * 不逃逸 —— 仅仅只在方法内被引用，不会被外部引用
> > * 方法逃逸 —— 被同线程的其他方法所引用
> > * 线程逃逸 —— 被其他线程所引用
> >
> > #### 栈上分配优化
> >
> > * 原理 —— 节省GC消耗
> > * 实现 —— 不逃逸和方法逃逸的对象可以在栈上分配而不在堆上分配
> > * 统计基础 —— 方法逃逸和不逃逸的对象所占比例其实是很大的
> >
> > #### 标量替换优化
> >
> > * 实质 —— 将一个java对象拆散，根据程序的访问情况，将其用到的成员变量恢复为原始类型
> > * 逃逸度 —— 不逃逸和方法逃逸
> >
> > #### 同步消除优化
> >
> > * 线程同步很耗时
> > * 然而如果某对象不线程逃逸则可能降低同步的概率
> >
> > #### 逃逸分析技术的实现困难
> >
> > * 逃逸分析理论很美好，但实现起来比较困难
> > * 逃逸分析要做大范围分析计算，这正是即时编译器的劣势
> > * 很可能计算代价高于逃逸分析优化的收获，反而得不偿失
> >
> > #### java栈内存的弱势
> >
> > * java运用栈内存方面弱势很大
> > * C和C++原生支持栈上分配(不用 new关键字就行)
> > * C#支持值类型，自然而然可以标量替换
> >
> > ***
>
> ### 公共子表达式消除
>
> > #### 概念
> >
> > * 如果一个表达式E已经被计算过了，且从先前计算到现在E中所有变量的值都没发生变化，那么E称为公共表达式
> >
> > #### 举例
> >
> > ```java
> > int d = (c * b) * 12 + a + (a +b * c);
> > 
> > int d = E * 12 + a +a +E;
> > 
> > int d = E * 13 + a + a;
> > ```
> >
> > ***
>
> ### 隐式异常处理
>
> > #### 目的
> >
> > * java中额外判断保证程序安全的代码很多
> > * 然而每次判断又是一笔不小的开销
> >
> > #### 面向情况
> >
> > * 数组边界检查
> > * 空指针
> > * 除零
> >
> > #### 举例
> >
> > ```java
> > try {
> >     return foo.value()
> > }else {
> >     uncommon_trap();
> > }
> > ```
> >
> > #### 分析
> >
> > * 只要没有异常，那就几乎没有检查开销
> > * 如果有异常，就要收到异常信号进入一个JVM注册的异常处理器
> > * 进入异常处理器必然涉及中断，用户态与核心态的切换
> > * 好在出异常的情况毕竟是少数
> >
> > ***
>
> ### JVMCI
>
> > #### 中文名
> >
> > * java虚拟机接口
> >
> > #### 出现背景
> >
> > * C1和C2编译器与HotSpot虚拟机高度耦合
> > * 导致加入Graal虚拟机困难，且耦合本身就不好
> > * 于是提出JVMCI
> >
> > #### 功能
> >
> > * 响应HotSpot的编译请求，并把请求分发给由Java语言实现的即时编译器
> > * 允许编译器访问HotSpot中与即时编译相关的所有信息，并提供这些信息在java语言层面的抽象表示
> > * 提供HotSpot的代码缓存给java端抽象表示，允许编译器部署编译完成的二进制机器码
> >
> > #### 功能三
> >
> > * 由于功能三，可以将HotSpot的编译器当静态即时编译器来用
> >
> > ***
>
> ### 代码中间表示
>
> > #### 编译器内部转换过程
> >
> > * 字节码 -> 理想图(程序依赖图PDG) -> 优化 -> 机器码
> >
> > #### 理性图
> >
> > * 将数据流图和控制流图合并到一起
> > * 用一种边来表示数据流向
> > * 另一种边来表示控制流向
> >
> > #### 注
> >
> > * 理想图是Graal编译器进行代码优化前的代码中间表示
> >
> > ***
>
> ### 代码优化与生成
>
> > #### 过程
> >
> > * Graal先将字节码转换为理想图
> >   * 转换过程类似于x86指令的操作
> > * 在对理想图进行精简(即代码优化)
> > * 由理想图转换为LIR(目标机器相关)
> > * 有HotSpot同一后端产生机器码
> >
> > #### 注
> >
> > * Graal编译器以及JVMCI的出现为学习和研究JVM代码编译与生成技术有着很大的帮助，之前是只能啃C++
> >
> > ***
>
> ***

## 第十二章 java内存模型与线程

> ### 前述
>
> > 并发处理的广泛应用是Amdahl定律代替摩尔定律成为计算机性能发展源动力的根本原因，也是人类压榨计算机性能的最有力武器
> >
> > ***
>
> ### 概述
>
> > #### 并发效率
> >
> > * 线程并发有条不紊，效率自然高
> > * 线程之间频繁争用数据，互相阻塞甚至死锁，效率自然低
> >
> > #### 框架
> >
> > * 中间件服务器、各种框架已经屏蔽了很多线程并发细节
> > * 让程序员更多去关注业务逻辑
> >
> > ***
>
> ### 硬件的效率与一致性
>
> > ####  缓存的一致性
> >
> > * 共享内存多核系统中每个处理器核拥有自己的高速缓存但共享主内存
> > * 当多个缓存映射到主存同一区域需要写回时就会出现缓存一致性问题
> > * 为解决一致性问题，采用的是读写必须遵守协议
> >
> > #### 内存模型
> >
> > * 在特定的操作协议下，对特定的内存或高速缓存进行读写的过程抽象
> >
> > #### 指令重排优化
> >
> > * 类似于处理器乱序执行优化
> >
> > ***
>
> ### java内存模型
>
> > #### JMM目标
> >
> > * 屏蔽各种硬件和操作系统的内存访问差异
> > * 实现java程序在各个平台下都能达到一致的内存访问效果
> >
> > #### C和C++内存模型
> >
> > * 直接使用物理硬件和操作系统的内存模型(可知移植性差)
> >
> > #### 宽松与严谨
> >
> > * 严谨 —— 让java的并发内存访问操作不会有歧义
> > * 宽松 —— 让JVM有足够自由度去使用硬件特性去提升性能
> >
> > ***
>
> ### 主内存与工作内存
>
> > #### JMM
> >
> > * 定义程序中各种变量的访问规则
> > * 此处变量指实例字段、静态字段、数组元素；不包括方法内局部变量(线程私有的)
> >
> > #### 主内存
> >
> > * 类比于物理机的主存
> > * 所有JMM定义的变量都要存在主存上
> >
> > #### 工作内存
> >
> > * 类比物理机的高速缓存
> > * 存了主内存变量的副本
> > * 是线程私有的
> > * 线程只能访问自己的工作内存，不能访问主存
> > * 线程间的变量传递要通过主存这个中介
> >
> > #### 对应关系
> >
> > * 主内存主要对应于java堆中对象实例的数据部分
> > * 工作内存对应于虚拟机栈的部分区域
> >
> > #### reference的非共享性
> >
> > * reference指向的对象是所有线程共享的
> > * 但reference这个引用本生是私有非共享的
> >
> > ***
>
> ### 内存间的交互操作
>
> > #### 8中操作
> >
> > * 定义了内存交互的8中操作
> > * 每一种操作都是原子性不可再分的
> >
> > #### 具体的8种操作
> >
> > * lock —— 锁定主内存一个变量
> > * unlock —— 解锁主内存一个变量
> > * read —— 读主内存一个变量
> > * load —— 从主内存载入一个变量到工作内存
> > * use —— 从工作内存传值给执行引擎
> > * assign —— 执行引擎赋值给工作内存变量
> > * store —— 工作内存传值给主内存
> > * write —— 写入主内存
> >
> > #### 满足规则
> >
> > * 不允许read，load和store，write其中之一单独出现
> > * 工作内存变量改变后必须同步回主内存
> > * 不能不assign之前把任意工作内存值同步回主内存
> > * 不允许在工作内存中使用未初始化变量
> > * 一个变量同一时刻只能被一条线程lock，且可被多次lock
> > * 执行lock操作后，必须清楚此变量在其他线程工作空间的值
> > * unlock之前必须同步回主存
> >
> > #### 语言层面简化
> >
> > * 由于规则太多太繁琐
> > * 在java语言层面上述内存模型规则被简化为read、write、lock、unlock
> > * 但实际内存模型层次并没有简化，只是语言层面简化而已
> >
> > ***
>
> ### volatile变量的特殊规则
>
> > #### JMM规定的volatile特点
> >
> > * 每次工作内存使用volatile变量之前都要从主存中刷新最新的值，保证可见性
> > * 每次工作内存中修改volatile变量之后都要立即同步回主内存
> > * 禁止指令重排序
> >
> > #### 理论与实际
> >
> > * 理论上volatile是实现并发的高效方式，但有时失效
> > * 比如 'race++'，此时race变量被声明生volatile
> > * 上面指令只能保证在读volatile时正确性，以及写回时会同步
> > * 但'++'操作不是原子性操作，之间还有其他的指令，且某些指令也不是原子性操作
> > * 因此在一次'race++'过程中读入和写出之间很可能race的值已经改变，导致并发失败
> >
> > #### 必须用锁来保证原子性情况
> >
> > * 运行结果并不依赖变量的当前值，或者能够确保只有单一线程修改变量的值
> >   * 如set()方法设置变量值
> > * 变量不需要与其他的状态变量共同参与不变约束
> > * 总结起来就是尽量加锁
> >
> > #### 指令重排导致并发失败
> >
> > * 指令重排可能导致关键的bool信号错误而并发失败
> > * 指令重排是并发编程程序员最疑惑的地方
> >
> > #### 双锁检测单例模式
> >
> > ```java
> > public class Singleton{
> >     public static volatile Singleton instance;
> >     public static Singleton getInstane(){
> >         if(instance == null){
> >             sychronized(Singleton.class){
> >                 if(instance == null)
> >                     instance = new Singleton;
> >             }
> >         }
> >         return instance;
> >     }
> > }
> > ```
> >
> > #### volatile与锁机制比较
> >
> > * volatile同步性能确实优于锁
> > * volatile读操作几乎和普通变量一样，写操作要慢一些(破坏指令重排)
> > * 性能消耗一般比锁低
> >
> > ***
>
> ### long和double的特殊规则
>
> > #### 特例
> >
> > * 允许读写64位未被声明为volatile的数据分为两次32位数据来进行读写
> > * 也就是破坏了load、use、assign、write的原子性
> >
> > #### 不必担心
> >
> > * 一般读写到一半的并发错误实际很少出现
> >
> > ***
>
> ### 原子性、可见性、有序性
>
> > #### 原子性
> >
> > * read、load、use、assign、store、write 这6中操作具有原子性
> > * 一般基本类型的读写具有原子性(64位几乎不影响)
> > * lock和unlock对象字节码指令monitorenter和monitorexit，提供了高层的synchronized关键字
> > * synchronized块也具有原子性
> >
> > #### 可见性
> >
> > * 概念 —— 当一个线程修改了共享变量的值后，其他线程能够立即看到此值的修改
> > * 实现 —— 修改后新值write回主内存，从主内存重新load进其他工作内存
> > * volatile与普通的区别 —— volatile保证了立即性，读时必须刷新，写时必须同步
> > * synchronized可见性 —— 因为unlock时必须同步写回
> > * final可见性 ——final关键字修饰字段也可以保证可见性
> >
> > #### 有序性
> >
> > * 线程类似表现为串行；指令重排，同步延迟看起来不是有序的
> > * volatile和synchronized都能保证有序性
> > * synchronized关键字是 '持有同一个锁的两个同步块只能串行进入'保证有序性
> >
> > #### 万能的synchronized
> >
> > * synchronized关键字能满足上面三条特性
> > * 看起来很万能，但越万能就意味着更大的性能开销
> >
> > ***
>
> ### 先行发生(Happens Before)原则
>
> > #### 本质
> >
> > * JMM定义的两项操作之间的偏序关系
> >
> > #### 天生先行发生原则
> >
> > * 值java中定义好的无需任何同步器就能直接使用的先行发生规则
> > * 不在此规则中或者无法由此规则推导而出就可能被JVM随意重排序
> >
> > #### 举例
> >
> > * 程序次序原则 —— 按照控制流，前面操作先行发生于后面操作
> > * 管程锁定规则 —— 对一个unlock操作先行发生于下一次lock操作
> > * volatile规则 —— 对一个volatile的写操作先行发生于后面对这个变量的读操作
> > * 线程启动规则 —— 线程start()方法先行发生于线程其他所有操作
> > * 传递性 —— 先行可以传递
> > * ……
> >
> > #### 先行原则举例
> >
> > ```java
> > public void setValue(int value){
> >     this.value = value;
> > }
> > public int getValue(){
> >     return this.value;
> > }
> > ```
> >
> > * 线程A和B分别执行set和get操作，且线程A执行set操作 '时间上先行与B'， 问能否保证并发正确？
> > * 不在同一线程，程序次序不适用
> > * 没有同步块，管程锁定lock不适用
> > * 没volatile，volatile不适用
> > * 没传递性，传递性不适用
> > * 因此尽管时间先发，但依然是线程不安全的
> > * 解决方案
> >   * 使用volatile修饰
> >   * 因为满足修改变量的值不依赖变量当前值的特点
> >
> > #### 时间先行与先行发生关系
> >
> > ```java
> > int i = 2;
> > int i = 3;
> > //先行发生不代表时间上先行，如指令重排，甚至可能不执行。
> > ```
> >
> > * 两者间没有因果关系
> > * 因此不能用时间先行来判断程序是否先行发生
> >
> > ***
>
> ### 线程的实现
>
> > #### 并发与线程的关系
> >
> > * 并发不一定依赖线程
> > * 如PHP中的多进程并发
> >
> > #### 封装性
> >
> > * java提供不同硬件和操作系统平台下对线程操作的统一处理
> > * 每个调用过start()方法且还没结束的java.lang.Thread对象实例就代表一个线程
> >
> > #### 实现线程的三种方式
> >
> > * 内核线程实现 1:1
> > * 用户线程实现 1:N
> > * 混合实现M:N
> >
> > #### 线程从低到高
> >
> > * 内核级线程KLT —— 由操作系统内核直接控制的线程
> > * 轻量级进程LWP —— 内核线程的高级接口实现，与内核线程1:1关系
> > * 用户线程 —— 建立在用户空间上的线程
> >
> > #### 内核线程实现
> >
> > * 每一个用户线程严格一一对应一条轻量级进程(然而轻量级进程又对应一条内核级线程)
> > * 此种模式下，一个进程由多条LWP组成
> > * 缺点是频繁系统调用，支持线程数较少
> > * 优点是进程调度全部交给操作系统，不用自己管
> >
> > #### 用户线程实现
> >
> > * 完全屏蔽了内核线程，内核线程完全感知不到用户线程的存在
> > * 此种模式下，一个进程由一条LWP组成，一个进程层次之上分为多个用户线程
> > * 缺点是各种调度自己实现
> > * 优点是不用频繁系统调用，可以支持线程规模条数很多
> >
> > #### 混合实现
> >
> > * 综合前面两种实现
> > * 多个LWP构成一个进程
> > * 一个进程之上又分为多个用户线程
> > * LWP充当用户线程与内核线程的桥梁
> >
> > #### java线程实现
> >
> > * HotSpot使用的是内核线程实现
> > * 操作系统支持怎样的线程模型，很大程序影响java线程如何映射
> > * java的线程实现对程序来说是完全透明的
> >
> > ***
>
> ### java线程调度
>
> > #### 协同式调度
> >
> > * 执行时间由线程本身决定，线程执行完后通知系统换另一个线程上去
> > * 优点：无线程同步问题(因为每个线程都要执行完才退出)
> > * 缺点：一旦阻塞整个系统就崩溃，如早期Windows
> >
> > #### 抢占式调度
> >
> > * 更偏向于平时所学习的处理器调度知识
> > * 线程执行时间不取决于线程而取决于系统分配，线程切换由系统调度完成
> > * 如Thread::yield()方法可以主动让出处理器时间
> > * 这是java使用的线程调度方案
> > * 缺点：有同步问题
> > * 优点：一个线程阻塞无所谓，如现在windows直接任务管理器杀死进程
> >
> > #### java线程优先级
> >
> > * 由于java采用内核级的线程实现，因此java一个线程就等同于操作系统下的一个内核进程
> > * 操作系统的内核线程优先等级很可能会与java语言中定义的线程优先度不能一一匹配
> > * 因此出现多个java线程优先级对应操作系统同一个内核线程优先级的情况
> > * 因此这种线程优先级调节不稳定
> > * 还有可能被操作系统层面直接修改优先级
> >   * 如操作系统发现某个内核线程(对应于java中的线程)执行太频繁，就会把其优先级调高，避免过多线程切换的开销
> >
> > ***
>
> ### 状态转换
>
> > #### 6种状态
> >
> > * new
> > * runnable —— 正在执行或ready等待执行
> > * 无限期等待waiting
> >   * 没有设置timeout参数的Object::wait()方法
> >   * 没有设置timeout参数的Thread::join()方法
> > * 限期等待 timed waiting
> >   * Thread::sleep()方法
> >   * 有设置timeout参数的Object::wait()方法
> >   * 有设置timeout参数的Thread::join()方法
> > * blocked
> > * terminated
> >
> > #### 转换关系
> >
> > * new -> runnalbe —— Thread::start()
> > * runnable -> blocked —— synchronized等其他阻塞
> > * runnable -> waiting —— Thread::wait() 没有timeout参数
> > * waiting -> runnale —— Object::notify()或者Object::notifyAll()
> > * ……
> >
> > ***
>
> ### 内核线程的局限性
>
> > #### 框架
> >
> > * 很多框架对线程做了大量的封装，让开发者很容易进行并发操作
> > * 然而在某些场景下已经显露疲态
> >
> > #### 分工式响应机制
> >
> > * 现如今的BS架构服务中，一次业务请求很可能需要分布在不用机器上的大量服务协作完成
> > * 优势
> >   * 单个服务复杂度低，复用性高，可支持请求多
> > * 劣势
> >   * 每个服务响应时间缩小
> >   * 要求每个服务响应都要迅速
> >
> > #### 1:1内核映射模型
> >
> > * 主流JVM依然使用1:1内核线程映射模型
> > * 缺点
> >   * 线程切换开销相对极大
> >   * 线程池数量规模太小
> > * 当线程池只有200，却承受百万计的请求时，即时抗住了，但线程开销实在太大
> >
> > ***
>
> ### 协程的复苏
>
> > #### 内核调度的高成本
> >
> > * 用户态，核心态的切换
> > * 响应中断，保护和恢复现场
> > * 程序上下文的恢复
> >   * 程序员角度 —— 方法调用的各种局部变量与资源
> >   * 线程角度 —— 方法调用栈
> >   * OS和硬件角度 —— 存储在内部和寄存器中的值
> >
> > #### 转换为用户线程就可以避免调度开销？
> >
> > * 不能避免
> > * 但在用户线程层面就有很多的处理空间，是开销降低
> >
> > #### 栈纠缠
> >
> > * 本质 —— 应用程序自己模拟多任务并行
> > * 实现 —— 将内存一块区域当做调用栈，只要压栈出栈符合规则，那多段程序就能够在一个栈内执行，相互纠缠
> >
> > #### 协程
> >
> > * 本质是采用协同式调度的用户线程，是一种应用程序级别的多线程
> > * 有栈协程 —— 会自己完整地做调用栈保护和恢复工作
> > * 无栈协程 —— 本质是一种简单自动机
> > * 优势 —— 栈容量小，一个协程池能容纳十万计的协程数
> >
> > #### 前景
> >
> > * 协程道阻且长
> > * java虚拟机栈和本地方法栈是一个栈，按协程调用本地方法如何处理？
> > * 协程同步如何处理？
> >
> > ***
>
> ### java解决方案
>
> > #### 纤程
> >
> > * 就是有栈协程
> > * 由JVM实现调度
> > * 是一种用户线程
> >
> > #### 优势
> >
> > * 并发能力大大提高
> >
> > #### 与线程关系
> >
> > * 它们是两套并发编程模型
> >
> > ***
>
> ***

## 第十三章 线程安全与锁优化

> #### 概述
>
> > #### 重要性
> >
> > * 并发先安全后高效
> >
> > ***
>
> ### 线程安全
>
> > #### 定义
> >
> > * 多个线程访问同一个对象时，如果不用考虑这些线程在运行时的调度与交替执行，也不需要额外的同步，或者在调用方进行任何的协调操作，调用这个对象的行为都能获得正确的结果。那么这个线程就是安全的
> >
> > #### 不可变
> >
> > * 不可变对象一定是线程安全的
> > * final基本数据类型 —— 肯定不可变安全
> > * final引用类型 —— 由于java没有提供值类型支持，则要对象自己保证自己行为不会对其状态产生影响
> > * 举例 —— String类，Number的大多数类
> >
> > #### 绝对线程安全
> >
> > * 这是《java并发编程实战》给的定义，十分苛刻
> > * 'java声明的线程安全类型' 与 '绝对线程安全的差异'
> >   * 绝对线程安全大于java声明的线程安全
> >   * 因为即使某个类所有方法和字段都声明为synchronized，但多线程访问此对象的时候没有加锁机制，仍然会导致并发不安全
> >   * 如java.lang.Vector是线程安全容器，但如果多线程访问时不加锁机制，依然会并发失败
> >
> > #### 相对线程安全
> >
> > * 就是普通意义下讲的线程安全
> > * 这种线程安全仅仅局限于对象的单次操作，多线程多次连续操作依然会并发失败
> >
> > #### 线程兼容
> >
> > * 本身不线程安全
> > * 但可以在调用端使用同步手段来保证对象在并发环境中使用
> > * java中大部分api都是线程兼容，如ArrayList和HashMap；而Vector和HashTable是相对线程安全的
> >
> > #### 线程队立
> >
> > * 调用端无论采取何种措施，都不可能多线程并发正确
> >
> > ***
>
> ### 线程安全的实现方法
>
> > #### 编码与底层
> >
> > * 实现线程安全与编码关系极大
> > * 但底层还是要使用JVM提供的同步和锁机制
> >
> > #### 互斥同步理论
> >
> > * 同步指同一时刻共享变量只能被一条线程使用
> > * 互斥是实现同步的手段。如临界区、信号量、互斥量
> > * 互斥是因，同步是果
> > * 互斥是方法，同步是目的
> >
> > #### synchronized关键字原理
> >
> > * 其是实现互斥同步的重要手段
> > * 它需要传入一个reference，即被上锁的对象
> > * reference可以是一个实例对象，可以是类的Class对象(同步类方法时)
> > * javac时生成monitorenter和monitorexit两条指令
> > * monitorenter时尝试获取锁，一旦获取或本来持有就把锁计数值加1
> > * monitorexit将锁计数值减少1
> >
> > #### synchronized特点
> >
> > * 允许一条线程多次进入，不会自己阻塞自己
> > * 会无条件阻塞其他无锁进程；且无法强制阻塞进程中断或超时退出
> > * 是一种块结构
> > * 是重量级的锁操作。因为由于内核线程映射的多线程模型，阻塞唤醒开销极大
> > * 鉴于性能影响严重，一般非必须不用；就算用JVM也会尽可能优化
> >
> > #### java.util.concurent.locks.Lock
> >
> > * 一种新的互斥同步手段
> > * 以非块结构实现互斥同步，改为在类库层面实现同步
> >
> > #### 重入锁
> >
> > * Lock接口的一个实现类
> > * 等待可中断性
> > * 公平性
> >   * 公平性指锁释放后根据阻塞线程先来后到顺序持有锁
> >   * synchronized默认非公平锁
> >   * 重入锁也是默认非公平锁，但可以设置成公平锁
> >   * 公平锁对性能影响很大
> > * 绑定多个条件
> >   * synchronized的模式限制了一个reference就需要一个锁
> >   * 而重入锁可以多次调用newCondition()方法添加锁定对象
> >
> > #### synchronized优势
> >
> > * 每个人都熟悉，更常用
> > * 不用手动释放锁，释放操作在JVM层面实现
> >
> > #### 非阻塞同步理论
> >
> > * 互斥同步称为阻塞同步
> > * 互斥同步是一种悲观的并发策略，总认为并发会出问题。增加了用户态核心态的转换、锁计数的维护
> > * 非阻塞同步是一种乐观并发策略，先认为没问题直接访问，有问题了在想补救措施。最常用的措施是重试
> > * 结果是线程不用被阻塞挂起，称为非阻塞同步
> > * 注意：重试操作需要硬件指令集的支持。因为必须保证操作和冲突检测这两个操作是原子性的
> >
> > #### 比较和交换(CAS)
> >
> > * 操作数
> >
> >   * 内存位置V
> >   * 旧值A
> >   * 新值B
> >
> > * 过程
> >
> >   * 想去把新值B赋给V
> >   * 首先检查旧值A是否相等，如果相等才更新，否则不更新
> >
> > * 此操作具有原子性
> >
> > * 自增举例
> >
> >   ```java
> >   while(true){
> >       int current = get();
> >       int next = corrent + 1;
> >       if(cma(this,current,next))
> >           return next;
> >   }
> >   ```
> >
> > #### 无同步方案
> >
> > * 同步与并发安全没有必然关系
> >
> > #### 线程本地存储
> >
> > * 如果一段代码中的数据需要与其他代码共享，那就看看这段代码是否可以只放在一个进程中执行。如果可以就放在一个进程中执行
> > * 如生产消费模式中要求消费过程必须在一个进程中消费完
> > * 如一个web请求对应一条服务器线程
> >
> > #### 线程本地存储实现
> >
> > * C++可以使用关键字限制一个变量被线程独享
> > * java使用java.lang.ThreadLocal实现
> > * 每个ThreadLocal对象都有一个map，这个map存储本地线程的变量值
> >
> > ***
>
> ### 自旋锁(spinning)与自适应自旋
>
> > #### 原理
> >
> > * 线程阻塞的开销很大
> > * 很多线程往往在多等待那么一会儿就能获得锁了，却不幸被阻塞又唤醒
> > * 且物理机一般都是多核，提供了让线程不阻塞继续自旋的条件
> >
> > #### 自旋缺点
> >
> > * 实际还是占用着处理器时间
> > * 自旋效果不好常常一直自旋但等不到锁，造成资源浪费
> >
> > #### 自适应自旋
> >
> > * 指自旋的次数动态调整
> > * 自旋一会儿就能及时获得锁的，下次让它多自旋一会儿
> > * 那些一直自旋结果也没用的干脆就别自旋了，下次直接挂起
> >
> > ***
>
> ### 锁消除
>
> > #### 内容
> >
> > * 即时编译时，对要求同步的一些代码，但检测到不可能出现共享数据竞争问题，就把锁消除
> >
> > #### 技术支持
> >
> > * 逃逸分析
> >
> > #### 为什么会有锁消除
> >
> > * 逃逸分析要做过程间分析，十分费时费资源
> > * 程序员为啥看不出来不会逃逸就不加锁？
> > * 因为java很多api库里面代码是上锁的，这些代码的锁很多可以消除
> >
> > #### 举例
> >
> > ```java
> > public String addString(String str1, String str2, String str3){
> >     return str1+str2+str3;
> > }
> > 
> > public String addString(String str1, String str2, String str3){
> >     StringBuilder builder = new StringBuilder();
> >     builder.append(str1);
> >     builder.append(str2);
> >     buidler.append(str3);
> >     return builder.toString();
> > }
> > ```
> >
> > * 'return str1+str2+str3;' 一句话拆成源码包含很多很多锁
> >
> > ***
>
> ### 锁粗化
>
> > #### 原理
> >
> > * 普遍常识认为锁的粒度越小越好，因为这样能更低频率地触发锁机制
> > * 但如果在一段代码内，频繁甚至循环对一个同步对象加锁上锁操作的话
> > * 频繁加锁上锁也会造成很大的性能开销
> > * 因此可以适当选择把锁的范围扩大，这样反而能获得更好的效率
> >
> > ***
>
> ### 轻量级锁
>
> > #### 轻量
> >
> > * 相对于传统使用操作系统互斥量的锁机制而言是“轻量”
> > * 目的不是代替重量级锁，而是减少操作系统互斥量的使用消耗
> >
> > #### 对象头内存布局
> >
> > * 对象头为了节省空间使信息比提高，以位为单位存储信息
> > * 32位机器对象头有32位；64位有64位
> > * 内容
> >   * 自身信息(Mark Word) —— 哈希值、GC分代年龄
> >   * 指向方法区Class对象的引用
> >   * 数组长度(只有数组才有)
> > * 不同状态下Mark Word的值会不一样
> >   * 未锁定
> >   * 轻量锁定
> >   * 重度锁定
> >   * GC标记
> >   * 可偏向
> >
> > #### 过程
> >
> > * 线程同步块，此时对象未被锁定处于未锁定状态
> > * 于是建立一个栈空间，用于存放对象头的拷贝
> > * 尝试使用CAP操作拷贝对象头到建立好的栈空间。如果成功该线程就拥有对象锁，且对象的对象头变为轻量锁状态
> > * 如果更新失败，就意味着被竞争，就直接采用重量锁，对象头改为重量锁状态，等待线程被阻塞
> > * 释放锁过程也是通过CAS操作完成，主要内容就是拷贝回原本对象头引用。
> > * 如果成功就同步结束，如果失败说明有线程被阻塞，释放锁时还要唤醒线程
> >
> > #### 总结
> >
> > * 轻量锁的依据是对于绝大部分的锁，整个同步周期都不存在竞争
> > * 如果真的不存在竞争，那么同步过程一次重量锁的操作系统互斥量都没有，节省了开销
> > * 但如果有竞争，轻量锁有开销，后面还是要用重量锁，开销就很大
> > * 所以在竞争激烈的情况下轻量锁会不好
> >
> > ***
>
> ### 偏向锁(Biased Locking)
>
> > #### 概念
> >
> > * 轻量锁是在无竞争情况下使用CAS操作消除同步互斥量的使用
> > * 偏向锁就是在无竞争的情况下把整个同步都消除掉
> > * 偏向指锁会偏向第一个获得它的线程，如果在接下来过程中根本没有竞争，那么就根本不用同步
> >
> > #### 过程
> >
> > * 使用CAS将获取这个锁的线程ID记录在Mark Word中。如果成功那就畅通无阻不用进行同步操作
> > * 撤销偏向锁原因
> >   * 有另一个线程尝试获取锁
> >   * 对象请求计算哈希码
> >
> > #### 递进关系
> >
> > * 偏向锁退化为轻量锁
> > * 轻量锁退化为重量锁
> >
> > #### 总结
> >
> > * 偏向锁能提高有同步但无竞争程序的效率
> > * 对有同步有竞争的程序有时关系此优化反而能获得更高的效率
> >
> > ***
>
> ***

## 展望java技术未来 —— 2013版本

> ### 模块化
>
> * OSGi和Oracle公司推的方案激烈竞争
> * OSGi几乎已成民间默认标准
>
> ### 混合语言
>
> * 基于java虚拟机语言越来越多
> * 专门语言干专门的事，彼此提供通用接口或成主流
> * 老语言也开始有JVM版本
>
> ### 多核并行
>
> * 并发性越来越重要
> * 函数式编程天生适合并发
> * 挖掘GPU潜力，不仅局限于CPU计算
> * 并行计算框架层出不穷
>
> ### 进一步丰富的语法
>
> * 面向函数式编程或许会成为主流
>
> ### 64位虚拟机的应用
>
> ***

